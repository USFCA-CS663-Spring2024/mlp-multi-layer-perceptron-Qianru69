{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bae43d2c-cfa1-40cc-8db2-8c664dcfe932",
        "d2da7441-10cf-4cb4-8c29-9ea6dfa50603",
        "7c937d7a-c58a-4794-a8d0-63d115b52656"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noted-template"
      },
      "source": [
        "# Assignment 4 - MLP Optimization\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bae43d2c-cfa1-40cc-8db2-8c664dcfe932"
      },
      "source": [
        "## Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-EhFqDNUM5e",
        "outputId": "fe984547-a422-4494-f3bb-07328b30ed8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/winequality-red.csv'"
      ],
      "metadata": {
        "id": "hQNxCQPDUTIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stopped-jewel",
        "outputId": "7060ea23-68e0-4b52-d33f-457153797c44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0               7.4             0.700         0.00             1.9      0.076   \n",
              "1               7.8             0.880         0.00             2.6      0.098   \n",
              "2               7.8             0.760         0.04             2.3      0.092   \n",
              "3              11.2             0.280         0.56             1.9      0.075   \n",
              "4               7.4             0.700         0.00             1.9      0.076   \n",
              "...             ...               ...          ...             ...        ...   \n",
              "1594            6.2             0.600         0.08             2.0      0.090   \n",
              "1595            5.9             0.550         0.10             2.2      0.062   \n",
              "1596            6.3             0.510         0.13             2.3      0.076   \n",
              "1597            5.9             0.645         0.12             2.0      0.075   \n",
              "1598            6.0             0.310         0.47             3.6      0.067   \n",
              "\n",
              "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
              "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
              "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
              "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
              "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
              "...                   ...                   ...      ...   ...        ...   \n",
              "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
              "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
              "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
              "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
              "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
              "\n",
              "      alcohol  quality  \n",
              "0         9.4        5  \n",
              "1         9.8        5  \n",
              "2         9.8        5  \n",
              "3         9.8        6  \n",
              "4         9.4        5  \n",
              "...       ...      ...  \n",
              "1594     10.5        5  \n",
              "1595     11.2        6  \n",
              "1596     11.0        6  \n",
              "1597     10.2        5  \n",
              "1598     11.0        6  \n",
              "\n",
              "[1599 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-faec0cdb-89b8-4e9e-8e83-7d948c0330a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99700</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1594</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.58</td>\n",
              "      <td>10.5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1595</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.062</td>\n",
              "      <td>39.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.99512</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.76</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1596</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.13</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.076</td>\n",
              "      <td>29.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.99574</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.75</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.645</td>\n",
              "      <td>0.12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.075</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99547</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.71</td>\n",
              "      <td>10.2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1598</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.47</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.067</td>\n",
              "      <td>18.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.99549</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.66</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1599 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-faec0cdb-89b8-4e9e-8e83-7d948c0330a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-faec0cdb-89b8-4e9e-8e83-7d948c0330a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-faec0cdb-89b8-4e9e-8e83-7d948c0330a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2444497a-90c2-47a6-9a71-d2c0d4a2ac0c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2444497a-90c2-47a6-9a71-d2c0d4a2ac0c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2444497a-90c2-47a6-9a71-d2c0d4a2ac0c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_97ba8b4f-9bd5-4e70-b1b6-65af6447e051\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_97ba8b4f-9bd5-4e70-b1b6-65af6447e051 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1599,\n  \"fields\": [\n    {\n      \"column\": \"fixed acidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7410963181276953,\n        \"min\": 4.6,\n        \"max\": 15.9,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          5.3,\n          12.7,\n          12.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volatile acidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17905970415353537,\n        \"min\": 0.12,\n        \"max\": 1.58,\n        \"num_unique_values\": 143,\n        \"samples\": [\n          1.025,\n          0.4,\n          0.87\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"citric acid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19480113740531857,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          0.37,\n          0.0,\n          0.09\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"residual sugar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4099280595072798,\n        \"min\": 0.9,\n        \"max\": 15.5,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          11.0,\n          3.0,\n          15.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chlorides\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0470653020100901,\n        \"min\": 0.012,\n        \"max\": 0.611,\n        \"num_unique_values\": 153,\n        \"samples\": [\n          0.096,\n          0.3429999999999999,\n          0.159\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"free sulfur dioxide\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.460156969809725,\n        \"min\": 1.0,\n        \"max\": 72.0,\n        \"num_unique_values\": 60,\n        \"samples\": [\n          11.0,\n          9.0,\n          32.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total sulfur dioxide\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.895324478299074,\n        \"min\": 6.0,\n        \"max\": 289.0,\n        \"num_unique_values\": 144,\n        \"samples\": [\n          68.0,\n          35.0,\n          101.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"density\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0018873339538425554,\n        \"min\": 0.99007,\n        \"max\": 1.00369,\n        \"num_unique_values\": 436,\n        \"samples\": [\n          0.99974,\n          1.0001,\n          0.99471\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15438646490354277,\n        \"min\": 2.74,\n        \"max\": 4.01,\n        \"num_unique_values\": 89,\n        \"samples\": [\n          3.07,\n          3.0,\n          3.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sulphates\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16950697959010996,\n        \"min\": 0.33,\n        \"max\": 2.0,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          1.07,\n          1.04,\n          1.18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alcohol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0656675818473946,\n        \"min\": 8.4,\n        \"max\": 14.9,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          8.5,\n          9.95,\n          9.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 8,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5,\n          6,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 630
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b39144dc-80db-4fa2-9c73-4dd8107b4f0c"
      },
      "source": [
        "The winequality-red dataset contains  1599 rows and 12 columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a4e28ee-c0a3-4455-92fa-778eb55ef178"
      },
      "source": [
        "## Prepare datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ac7e419-c105-4f8e-842e-a2e025f7d89a"
      },
      "source": [
        "* Separate X, features and y, target column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f96f68d-1241-4f16-a992-2952ec9e1e14"
      },
      "outputs": [],
      "source": [
        "X, y = df.iloc[:, :-1], df.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c995e227-0f44-48cb-8539-a7b212f6904b",
        "outputId": "dae5a505-377a-47d0-9b42-5aa704a48891"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0               7.4             0.700         0.00             1.9      0.076   \n",
              "1               7.8             0.880         0.00             2.6      0.098   \n",
              "2               7.8             0.760         0.04             2.3      0.092   \n",
              "3              11.2             0.280         0.56             1.9      0.075   \n",
              "4               7.4             0.700         0.00             1.9      0.076   \n",
              "...             ...               ...          ...             ...        ...   \n",
              "1594            6.2             0.600         0.08             2.0      0.090   \n",
              "1595            5.9             0.550         0.10             2.2      0.062   \n",
              "1596            6.3             0.510         0.13             2.3      0.076   \n",
              "1597            5.9             0.645         0.12             2.0      0.075   \n",
              "1598            6.0             0.310         0.47             3.6      0.067   \n",
              "\n",
              "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
              "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
              "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
              "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
              "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
              "...                   ...                   ...      ...   ...        ...   \n",
              "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
              "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
              "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
              "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
              "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
              "\n",
              "      alcohol  \n",
              "0         9.4  \n",
              "1         9.8  \n",
              "2         9.8  \n",
              "3         9.8  \n",
              "4         9.4  \n",
              "...       ...  \n",
              "1594     10.5  \n",
              "1595     11.2  \n",
              "1596     11.0  \n",
              "1597     10.2  \n",
              "1598     11.0  \n",
              "\n",
              "[1599 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9359b24-bdc4-4fe8-bd01-fa7bc5deeb6f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99700</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1594</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.58</td>\n",
              "      <td>10.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1595</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.062</td>\n",
              "      <td>39.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.99512</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.76</td>\n",
              "      <td>11.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1596</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.13</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.076</td>\n",
              "      <td>29.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.99574</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.75</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.645</td>\n",
              "      <td>0.12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.075</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99547</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.71</td>\n",
              "      <td>10.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1598</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.47</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.067</td>\n",
              "      <td>18.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.99549</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.66</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1599 rows × 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9359b24-bdc4-4fe8-bd01-fa7bc5deeb6f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f9359b24-bdc4-4fe8-bd01-fa7bc5deeb6f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f9359b24-bdc4-4fe8-bd01-fa7bc5deeb6f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-95e3fb5c-28f1-44f3-9020-f53c37350c97\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-95e3fb5c-28f1-44f3-9020-f53c37350c97')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-95e3fb5c-28f1-44f3-9020-f53c37350c97 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_aeee8b2a-7eeb-4443-8a63-4061b89a91d2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_aeee8b2a-7eeb-4443-8a63-4061b89a91d2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 1599,\n  \"fields\": [\n    {\n      \"column\": \"fixed acidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7410963181276953,\n        \"min\": 4.6,\n        \"max\": 15.9,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          5.3,\n          12.7,\n          12.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volatile acidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17905970415353537,\n        \"min\": 0.12,\n        \"max\": 1.58,\n        \"num_unique_values\": 143,\n        \"samples\": [\n          1.025,\n          0.4,\n          0.87\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"citric acid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19480113740531857,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          0.37,\n          0.0,\n          0.09\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"residual sugar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4099280595072798,\n        \"min\": 0.9,\n        \"max\": 15.5,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          11.0,\n          3.0,\n          15.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chlorides\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0470653020100901,\n        \"min\": 0.012,\n        \"max\": 0.611,\n        \"num_unique_values\": 153,\n        \"samples\": [\n          0.096,\n          0.3429999999999999,\n          0.159\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"free sulfur dioxide\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.460156969809725,\n        \"min\": 1.0,\n        \"max\": 72.0,\n        \"num_unique_values\": 60,\n        \"samples\": [\n          11.0,\n          9.0,\n          32.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total sulfur dioxide\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.895324478299074,\n        \"min\": 6.0,\n        \"max\": 289.0,\n        \"num_unique_values\": 144,\n        \"samples\": [\n          68.0,\n          35.0,\n          101.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"density\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0018873339538425554,\n        \"min\": 0.99007,\n        \"max\": 1.00369,\n        \"num_unique_values\": 436,\n        \"samples\": [\n          0.99974,\n          1.0001,\n          0.99471\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15438646490354277,\n        \"min\": 2.74,\n        \"max\": 4.01,\n        \"num_unique_values\": 89,\n        \"samples\": [\n          3.07,\n          3.0,\n          3.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sulphates\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16950697959010996,\n        \"min\": 0.33,\n        \"max\": 2.0,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          1.07,\n          1.04,\n          1.18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alcohol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0656675818473946,\n        \"min\": 8.4,\n        \"max\": 14.9,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          8.5,\n          9.95,\n          9.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 632
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d7c60df-67b1-4f8a-8bb3-453edf9fa28f",
        "outputId": "bf32c7be-99c4-4839-c2ab-692cb6a60e99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       5\n",
              "1       5\n",
              "2       5\n",
              "3       6\n",
              "4       5\n",
              "       ..\n",
              "1594    5\n",
              "1595    6\n",
              "1596    6\n",
              "1597    5\n",
              "1598    6\n",
              "Name: quality, Length: 1599, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 633
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4af4894-72ef-4f70-9359-27cf09659f10"
      },
      "source": [
        "* Split to get 70% training set and 30% test + valid sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99971f98-92be-4782-ba2c-dd4605b93af6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, ee_x, y_train, ee_y = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c4815a2-a842-4257-bd1c-fa4bf43864dd",
        "outputId": "458c8435-260b-4d16-d378-6c8222c1e0b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1119, 11)\n",
            "(1119,)\n",
            "(480, 11)\n",
            "(480,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(ee_x.shape)\n",
        "print(ee_y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06392c2d-f16f-4807-b047-8208e55f8491"
      },
      "source": [
        "* Split to get the 15% test set and 15% validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32313bca-f085-4217-b925-5963aaba63e7"
      },
      "outputs": [],
      "source": [
        "x_valid, x_test, y_valid, y_test = train_test_split(ee_x, ee_y, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5f88263-a402-4445-89b9-7173bfbaa82b",
        "outputId": "fde32793-5433-4a2b-fc60-4b3b299419e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(240, 11)\n",
            "(240,)\n",
            "(240, 11)\n",
            "(240,)\n"
          ]
        }
      ],
      "source": [
        "print(x_valid.shape)\n",
        "print(y_valid.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Normalization"
      ],
      "metadata": {
        "id": "ufqdRUN_bQKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler_X_ss = StandardScaler()\n",
        "train_x_ss = scaler_X_ss.fit_transform(x_train)\n",
        "valid_x_ss = scaler_X_ss.transform(x_valid)\n",
        "test_x_ss = scaler_X_ss.transform(x_test)"
      ],
      "metadata": {
        "id": "hlBr5NombShG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler_X_mm = MinMaxScaler()\n",
        "train_x_mm = scaler_X_mm.fit_transform(x_train)\n",
        "valid_x_mm = scaler_X_mm.transform(x_valid)\n",
        "test_x_mm = scaler_X_mm.transform(x_test)"
      ],
      "metadata": {
        "id": "xGcJ0VfZbsLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2da7441-10cf-4cb4-8c29-9ea6dfa50603"
      },
      "source": [
        "## Convert data into tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7359cfe-3ba0-4253-8785-fd2aa3133440",
        "outputId": "351919a2-49f4-4f34-d12c-76c072cd0f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 8.6000,  0.2200,  0.3600,  ...,  3.4700,  0.8700, 11.0000],\n",
            "        [12.5000,  0.4600,  0.6300,  ...,  2.9900,  0.8700, 10.2000],\n",
            "        [ 7.2000,  0.5400,  0.2700,  ...,  3.3900,  0.7100, 11.0000],\n",
            "        ...,\n",
            "        [ 7.2000,  0.6200,  0.0600,  ...,  3.5100,  0.5400,  9.5000],\n",
            "        [ 7.9000,  0.2000,  0.3500,  ...,  3.3200,  0.8000, 11.9000],\n",
            "        [ 5.8000,  0.2900,  0.2600,  ...,  3.3900,  0.5400, 13.5000]])\n",
            "tensor([[ 7.6000,  0.6850,  0.2300,  ...,  3.2100,  0.6100,  9.3000],\n",
            "        [ 8.3000,  0.6100,  0.3000,  ...,  3.4000,  0.6100, 10.2000],\n",
            "        [ 6.6000,  0.7250,  0.0900,  ...,  3.3500,  0.4900, 10.8000],\n",
            "        ...,\n",
            "        [ 7.2000,  0.5700,  0.0500,  ...,  3.3800,  0.6000, 10.3000],\n",
            "        [ 9.9000,  0.5900,  0.0700,  ...,  3.3100,  0.7100,  9.8000],\n",
            "        [ 9.6000,  0.5000,  0.3600,  ...,  3.1800,  0.6800, 10.9000]])\n",
            "tensor([[ 6.1000,  0.4800,  0.0900,  ...,  3.4500,  0.5400, 11.2000],\n",
            "        [ 6.1000,  0.7150,  0.1000,  ...,  3.5700,  0.5000, 11.9000],\n",
            "        [ 5.4000,  0.4200,  0.2700,  ...,  3.7800,  0.6400, 12.3000],\n",
            "        ...,\n",
            "        [ 9.4000,  0.4000,  0.3100,  ...,  3.0700,  0.6300, 10.5000],\n",
            "        [ 6.2000,  0.7850,  0.0000,  ...,  3.5900,  0.6100, 10.0000],\n",
            "        [ 5.7000,  0.6000,  0.0000,  ...,  3.4500,  0.5600, 12.2000]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "train_x = torch.tensor(x_train.to_numpy())\n",
        "train_x = train_x.float()\n",
        "valid_x = torch.tensor(x_valid.to_numpy())\n",
        "valid_x = valid_x.float()\n",
        "test_x = torch.tensor(x_test.to_numpy())\n",
        "test_x = test_x.float()\n",
        "print(train_x)\n",
        "print(valid_x)\n",
        "print(test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16Lh7jumbShG",
        "outputId": "12874cd3-6f4d-4862-aef4-32db792606e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.6954e-01, -1.7211e+00,  4.5930e-01,  ...,  1.0118e+00,\n",
            "          1.2266e+00,  5.5006e-01],\n",
            "        [ 2.4461e+00, -4.0196e-01,  1.8411e+00,  ..., -2.1069e+00,\n",
            "          1.2266e+00, -2.0517e-01],\n",
            "        [-6.4768e-01,  3.7747e-02, -1.2805e-03,  ...,  4.9203e-01,\n",
            "          2.9727e-01,  5.5006e-01],\n",
            "        ...,\n",
            "        [-6.4768e-01,  4.7745e-01, -1.0760e+00,  ...,  1.2717e+00,\n",
            "         -6.9015e-01, -8.6600e-01],\n",
            "        [-2.3907e-01, -1.8310e+00,  4.0813e-01,  ...,  3.7218e-02,\n",
            "          8.2003e-01,  1.3997e+00],\n",
            "        [-1.4649e+00, -1.3363e+00, -5.2457e-02,  ...,  4.9203e-01,\n",
            "         -6.9015e-01,  2.9102e+00]])\n",
            "tensor([[-0.4142,  0.8347, -0.2060,  ..., -0.6775, -0.2836, -1.0548],\n",
            "        [-0.0056,  0.4225,  0.1522,  ...,  0.5570, -0.2836, -0.2052],\n",
            "        [-0.9979,  1.0546, -0.9224,  ...,  0.2321, -0.9806,  0.3612],\n",
            "        ...,\n",
            "        [-0.6477,  0.2026, -1.1272,  ...,  0.4271, -0.3417, -0.1108],\n",
            "        [ 0.9284,  0.3126, -1.0248,  ..., -0.0278,  0.2973, -0.5828],\n",
            "        [ 0.7533, -0.1821,  0.4593,  ..., -0.8724,  0.1230,  0.4557]])\n",
            "tensor([[-1.2898e+00, -2.9203e-01, -9.2245e-01,  ...,  8.8186e-01,\n",
            "         -6.9015e-01,  7.3886e-01],\n",
            "        [-1.2898e+00,  9.9960e-01, -8.7127e-01,  ...,  1.6615e+00,\n",
            "         -9.2249e-01,  1.3997e+00],\n",
            "        [-1.6984e+00, -6.2181e-01, -1.2805e-03,  ...,  3.0260e+00,\n",
            "         -1.0932e-01,  1.7773e+00],\n",
            "        ...,\n",
            "        [ 6.3652e-01, -7.3174e-01,  2.0342e-01,  ..., -1.5871e+00,\n",
            "         -1.6740e-01,  7.8037e-02],\n",
            "        [-1.2314e+00,  1.3843e+00, -1.3830e+00,  ...,  1.7915e+00,\n",
            "         -2.8357e-01, -3.9398e-01],\n",
            "        [-1.5233e+00,  3.6753e-01, -1.3830e+00,  ...,  8.8186e-01,\n",
            "         -5.7399e-01,  1.6829e+00]])\n"
          ]
        }
      ],
      "source": [
        "train_x_ss = torch.tensor(train_x_ss)\n",
        "train_x_ss = train_x_ss.float()\n",
        "valid_x_ss = torch.tensor(valid_x_ss)\n",
        "valid_x_ss = valid_x_ss.float()\n",
        "test_x_ss = torch.tensor(test_x_ss)\n",
        "test_x_ss = test_x_ss.float()\n",
        "print(train_x_ss)\n",
        "print(valid_x_ss)\n",
        "print(test_x_ss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_mm = torch.tensor(train_x_mm)\n",
        "train_x_mm = train_x_mm.float()\n",
        "valid_x_mm = torch.tensor(valid_x_mm)\n",
        "valid_x_mm = valid_x_mm.float()\n",
        "test_x_mm = torch.tensor(test_x_mm)\n",
        "test_x_mm = test_x_mm.float()\n",
        "print(train_x_mm)\n",
        "print(valid_x_mm)\n",
        "print(test_x_mm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3OagWYocS7i",
        "outputId": "2cb79bf7-e66a-46f1-8131-06bec9290f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3540, 0.0685, 0.3600,  ..., 0.5748, 0.3067, 0.4000],\n",
            "        [0.6991, 0.2329, 0.6300,  ..., 0.1969, 0.3067, 0.2769],\n",
            "        [0.2301, 0.2877, 0.2700,  ..., 0.5118, 0.2086, 0.4000],\n",
            "        ...,\n",
            "        [0.2301, 0.3425, 0.0600,  ..., 0.6063, 0.1043, 0.1692],\n",
            "        [0.2920, 0.0548, 0.3500,  ..., 0.4567, 0.2638, 0.5385],\n",
            "        [0.1062, 0.1164, 0.2600,  ..., 0.5118, 0.1043, 0.7846]])\n",
            "tensor([[0.2655, 0.3870, 0.2300,  ..., 0.3701, 0.1472, 0.1385],\n",
            "        [0.3274, 0.3356, 0.3000,  ..., 0.5197, 0.1472, 0.2769],\n",
            "        [0.1770, 0.4144, 0.0900,  ..., 0.4803, 0.0736, 0.3692],\n",
            "        ...,\n",
            "        [0.2301, 0.3082, 0.0500,  ..., 0.5039, 0.1411, 0.2923],\n",
            "        [0.4690, 0.3219, 0.0700,  ..., 0.4488, 0.2086, 0.2154],\n",
            "        [0.4425, 0.2603, 0.3600,  ..., 0.3465, 0.1902, 0.3846]])\n",
            "tensor([[0.1327, 0.2466, 0.0900,  ..., 0.5591, 0.1043, 0.4308],\n",
            "        [0.1327, 0.4075, 0.1000,  ..., 0.6535, 0.0798, 0.5385],\n",
            "        [0.0708, 0.2055, 0.2700,  ..., 0.8189, 0.1656, 0.6000],\n",
            "        ...,\n",
            "        [0.4248, 0.1918, 0.3100,  ..., 0.2598, 0.1595, 0.3231],\n",
            "        [0.1416, 0.4555, 0.0000,  ..., 0.6693, 0.1472, 0.2462],\n",
            "        [0.0973, 0.3288, 0.0000,  ..., 0.5591, 0.1166, 0.5846]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27ba7a66-bef6-4171-ba8e-ac4f28cc47e7"
      },
      "outputs": [],
      "source": [
        "train_y, valid_y, test_y = map(torch.tensor, (y_train.to_numpy().reshape(-1,1), y_valid.to_numpy().reshape(-1,1), y_test.to_numpy().reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b857cd9-d25b-491b-ac0d-b6220a692376"
      },
      "outputs": [],
      "source": [
        "train_y = train_y.float()\n",
        "valid_y = valid_y.float()\n",
        "test_y = test_y.float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "406bae21-b8c5-48eb-acd9-ba8481c39172",
        "outputId": "bc521018-10f6-4b56-db3f-06065aa9e9d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7.],\n",
              "        [5.],\n",
              "        [5.],\n",
              "        ...,\n",
              "        [5.],\n",
              "        [7.],\n",
              "        [6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 645
        }
      ],
      "source": [
        "train_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c937d7a-c58a-4794-a8d0-63d115b52656"
      },
      "source": [
        "## Set up the dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56a49818-a24b-476e-9f46-dd386e7d4805"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class WineQualityDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.x = X\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2c9870d-51c2-40c9-bb28-e28b30c6489b"
      },
      "outputs": [],
      "source": [
        "train_data = WineQualityDataset(train_x, train_y)\n",
        "valid_data = WineQualityDataset(valid_x, valid_y)\n",
        "test_data = WineQualityDataset(test_x, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_ss = WineQualityDataset(train_x_ss, train_y)\n",
        "train_data_mm = WineQualityDataset(train_x_mm, train_y)"
      ],
      "metadata": {
        "id": "h0DnQToKeqTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 853,
      "metadata": {
        "id": "17002608-4105-4396-bf05-5362fbeb9617"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#train_loader = DataLoader(dataset=train_data, batch_size=8)\n",
        "#train_loader_ss = DataLoader(dataset=train_data_ss, batch_size=8)\n",
        "#train_loader_mm = DataLoader(dataset=train_data_mm, batch_size=8)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=8, shuffle=True)\n",
        "train_loader_ss = DataLoader(dataset=train_data_ss, batch_size=8, shuffle=True)\n",
        "train_loader_mm = DataLoader(dataset=train_data_mm, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00f5e6fc-a3b0-4d88-b1a7-f7d03ab4be74"
      },
      "source": [
        "## Optimize MLP model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97c42793-64ab-4fcd-a567-a731f9c0d088"
      },
      "source": [
        "### Set up MLP class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 854,
      "metadata": {
        "id": "f9589f09-58e2-4fe2-bb65-da0ca030a169"
      },
      "outputs": [],
      "source": [
        "class WineQualityMLPBasic(torch.nn.Module):\n",
        "    def __init__(self, n_inputs, hidden_size, n_outputs):\n",
        "        super(WineQualityMLPBasic, self).__init__()\n",
        "        self.input = n_inputs\n",
        "        self.hidden = hidden_size\n",
        "        self.outputs = n_outputs\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(self.input, self.hidden)\n",
        "        self.fc2 = torch.nn.Linear(self.hidden, self.outputs)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = self.fc1(X)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WineQualityMLPTuning(torch.nn.Module):\n",
        "    def __init__(self, n_inputs, hidden_size, n_outputs, activation='relu', dropout_rate=0.5):\n",
        "        super(WineQualityMLPTuning, self).__init__()\n",
        "        self.input = n_inputs\n",
        "        self.hidden = hidden_size\n",
        "        self.outputs = n_outputs\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(self.input, self.hidden)\n",
        "        self.fc2 = torch.nn.Linear(self.hidden, self.hidden)\n",
        "        self.fc3 = torch.nn.Linear(self.hidden, self.outputs)\n",
        "        self.dropout = torch.nn.Dropout(p=dropout_rate)\n",
        "        self.dropout = torch.nn.Dropout(p=dropout_rate)\n",
        "\n",
        "        # Activation function selection\n",
        "        if activation == 'sigmoid':\n",
        "          self.activation = torch.nn.Sigmoid()\n",
        "        elif activation == 'tanh':\n",
        "          self.activation = torch.nn.Tanh()\n",
        "        else:\n",
        "          self.activation = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = self.fc1(X)\n",
        "        out = self.activation(out)\n",
        "        out = self.dropout(out)  # Apply dropout after activation\n",
        "        out = self.fc2(out)\n",
        "        out = self.activation(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "qEL7VvMthCF-"
      },
      "execution_count": 855,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 856,
      "metadata": {
        "scrolled": true,
        "id": "a49a9e3b-edf2-4c93-8da3-3859b678e17f"
      },
      "outputs": [],
      "source": [
        "def MLPtraining (epochs, model, train_loader, valid_x, valid_y, optimiser, criterion, early_stop=10):\n",
        "  train_loss = []\n",
        "  valid_loss = []\n",
        "  best_valid_loss = float('inf')\n",
        "  early_stopping_counter = 0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      print(epoch)\n",
        "      batch_loss = []\n",
        "      # Training batch\n",
        "      for features, targets in train_loader:\n",
        "          # Get output\n",
        "          output = model.forward(features)\n",
        "          # Calculate the loss\n",
        "          loss = criterion(output, targets)\n",
        "          batch_loss.append(loss.item())\n",
        "          optimiser.zero_grad() # Remove previous gradients\n",
        "          loss.backward() # What the updates should be\n",
        "          optimiser.step() # Update w&b\n",
        "      # for each epoch\n",
        "      # Training loss\n",
        "      train_loss.append(sum(batch_loss)/len(batch_loss))\n",
        "\n",
        "      # Valid loss, etc\n",
        "      hyp_valid = model.forward(valid_x)\n",
        "\n",
        "      epoch_valid_loss = criterion(hyp_valid, valid_y).item()\n",
        "      valid_loss.append(epoch_valid_loss)\n",
        "      print(\"Valid loss:\", valid_loss[-1])\n",
        "\n",
        "      # Early stopping logic\n",
        "      if epoch_valid_loss < best_valid_loss:\n",
        "          best_valid_loss = epoch_valid_loss\n",
        "          early_stopping_counter = 0  # reset the patience counter\n",
        "          print(\"Validation loss decreased\")\n",
        "      else:\n",
        "          early_stopping_counter += 1\n",
        "          print(f\"Validation loss did not improve. {early_stopping_counter}/{early_stop}\")\n",
        "          if early_stopping_counter >= early_stop:\n",
        "              print(\"Early stopping triggered.\")\n",
        "              break\n",
        "\n",
        "  return train_loss, valid_loss, epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning\n"
      ],
      "metadata": {
        "id": "OZ5HsMHkhT1R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 921,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "312e556b-6d31-441b-916c-70bbee2f67c1",
        "outputId": "95fbd6a4-0891-400f-f4d8-965cd367818d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WineQualityMLPTuning(\n",
              "  (fc1): Linear(in_features=11, out_features=5, bias=True)\n",
              "  (fc2): Linear(in_features=5, out_features=5, bias=True)\n",
              "  (fc3): Linear(in_features=5, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0, inplace=False)\n",
              "  (activation): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 921
        }
      ],
      "source": [
        "model = WineQualityMLPTuning(11, 5, 1, 'relu', 0)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 922,
      "metadata": {
        "id": "4d1fb9d6-40a7-44a1-80a0-3e17663ba8fd"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.MSELoss()\n",
        "optimiser = torch.optim.SGD(params=model.parameters(), lr=0.0001, momentum=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and generate plots"
      ],
      "metadata": {
        "id": "C3eXmuF_UVmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5000\n",
        "train_loss, valid_loss, stopping = MLPtraining (epochs, model, train_loader_ss, valid_x_ss, valid_y, optimiser, criterion, 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6Xk_VOkJgDS",
        "outputId": "dba084b8-3a59-41f2-b2d0-2860339275ca"
      },
      "execution_count": 923,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Valid loss: 31.515214920043945\n",
            "Validation loss decreased\n",
            "1\n",
            "Valid loss: 28.200748443603516\n",
            "Validation loss decreased\n",
            "2\n",
            "Valid loss: 24.774024963378906\n",
            "Validation loss decreased\n",
            "3\n",
            "Valid loss: 21.149503707885742\n",
            "Validation loss decreased\n",
            "4\n",
            "Valid loss: 17.350440979003906\n",
            "Validation loss decreased\n",
            "5\n",
            "Valid loss: 13.50740909576416\n",
            "Validation loss decreased\n",
            "6\n",
            "Valid loss: 9.863242149353027\n",
            "Validation loss decreased\n",
            "7\n",
            "Valid loss: 6.719729423522949\n",
            "Validation loss decreased\n",
            "8\n",
            "Valid loss: 4.327644348144531\n",
            "Validation loss decreased\n",
            "9\n",
            "Valid loss: 2.731961488723755\n",
            "Validation loss decreased\n",
            "10\n",
            "Valid loss: 1.799747109413147\n",
            "Validation loss decreased\n",
            "11\n",
            "Valid loss: 1.3048113584518433\n",
            "Validation loss decreased\n",
            "12\n",
            "Valid loss: 1.0523648262023926\n",
            "Validation loss decreased\n",
            "13\n",
            "Valid loss: 0.916161298751831\n",
            "Validation loss decreased\n",
            "14\n",
            "Valid loss: 0.8377494812011719\n",
            "Validation loss decreased\n",
            "15\n",
            "Valid loss: 0.7855939865112305\n",
            "Validation loss decreased\n",
            "16\n",
            "Valid loss: 0.7454493045806885\n",
            "Validation loss decreased\n",
            "17\n",
            "Valid loss: 0.713885486125946\n",
            "Validation loss decreased\n",
            "18\n",
            "Valid loss: 0.6885659098625183\n",
            "Validation loss decreased\n",
            "19\n",
            "Valid loss: 0.6659662127494812\n",
            "Validation loss decreased\n",
            "20\n",
            "Valid loss: 0.6462829113006592\n",
            "Validation loss decreased\n",
            "21\n",
            "Valid loss: 0.6289367079734802\n",
            "Validation loss decreased\n",
            "22\n",
            "Valid loss: 0.6138527393341064\n",
            "Validation loss decreased\n",
            "23\n",
            "Valid loss: 0.5998744964599609\n",
            "Validation loss decreased\n",
            "24\n",
            "Valid loss: 0.5870262980461121\n",
            "Validation loss decreased\n",
            "25\n",
            "Valid loss: 0.575499415397644\n",
            "Validation loss decreased\n",
            "26\n",
            "Valid loss: 0.5648205876350403\n",
            "Validation loss decreased\n",
            "27\n",
            "Valid loss: 0.5548974275588989\n",
            "Validation loss decreased\n",
            "28\n",
            "Valid loss: 0.5458945631980896\n",
            "Validation loss decreased\n",
            "29\n",
            "Valid loss: 0.537654459476471\n",
            "Validation loss decreased\n",
            "30\n",
            "Valid loss: 0.5301278829574585\n",
            "Validation loss decreased\n",
            "31\n",
            "Valid loss: 0.5232377648353577\n",
            "Validation loss decreased\n",
            "32\n",
            "Valid loss: 0.5165892243385315\n",
            "Validation loss decreased\n",
            "33\n",
            "Valid loss: 0.5108161568641663\n",
            "Validation loss decreased\n",
            "34\n",
            "Valid loss: 0.5052604079246521\n",
            "Validation loss decreased\n",
            "35\n",
            "Valid loss: 0.5000731945037842\n",
            "Validation loss decreased\n",
            "36\n",
            "Valid loss: 0.4949913024902344\n",
            "Validation loss decreased\n",
            "37\n",
            "Valid loss: 0.4906110465526581\n",
            "Validation loss decreased\n",
            "38\n",
            "Valid loss: 0.4865029752254486\n",
            "Validation loss decreased\n",
            "39\n",
            "Valid loss: 0.48248133063316345\n",
            "Validation loss decreased\n",
            "40\n",
            "Valid loss: 0.4788285195827484\n",
            "Validation loss decreased\n",
            "41\n",
            "Valid loss: 0.47522708773612976\n",
            "Validation loss decreased\n",
            "42\n",
            "Valid loss: 0.4719058871269226\n",
            "Validation loss decreased\n",
            "43\n",
            "Valid loss: 0.46872490644454956\n",
            "Validation loss decreased\n",
            "44\n",
            "Valid loss: 0.46580538153648376\n",
            "Validation loss decreased\n",
            "45\n",
            "Valid loss: 0.46285152435302734\n",
            "Validation loss decreased\n",
            "46\n",
            "Valid loss: 0.46030566096305847\n",
            "Validation loss decreased\n",
            "47\n",
            "Valid loss: 0.45773664116859436\n",
            "Validation loss decreased\n",
            "48\n",
            "Valid loss: 0.45539945363998413\n",
            "Validation loss decreased\n",
            "49\n",
            "Valid loss: 0.45295464992523193\n",
            "Validation loss decreased\n",
            "50\n",
            "Valid loss: 0.450880229473114\n",
            "Validation loss decreased\n",
            "51\n",
            "Valid loss: 0.44881612062454224\n",
            "Validation loss decreased\n",
            "52\n",
            "Valid loss: 0.4467834532260895\n",
            "Validation loss decreased\n",
            "53\n",
            "Valid loss: 0.44496098160743713\n",
            "Validation loss decreased\n",
            "54\n",
            "Valid loss: 0.4431728720664978\n",
            "Validation loss decreased\n",
            "55\n",
            "Valid loss: 0.4413931667804718\n",
            "Validation loss decreased\n",
            "56\n",
            "Valid loss: 0.4397139847278595\n",
            "Validation loss decreased\n",
            "57\n",
            "Valid loss: 0.4380802512168884\n",
            "Validation loss decreased\n",
            "58\n",
            "Valid loss: 0.436764121055603\n",
            "Validation loss decreased\n",
            "59\n",
            "Valid loss: 0.43513551354408264\n",
            "Validation loss decreased\n",
            "60\n",
            "Valid loss: 0.433673232793808\n",
            "Validation loss decreased\n",
            "61\n",
            "Valid loss: 0.43234488368034363\n",
            "Validation loss decreased\n",
            "62\n",
            "Valid loss: 0.43118664622306824\n",
            "Validation loss decreased\n",
            "63\n",
            "Valid loss: 0.4298444986343384\n",
            "Validation loss decreased\n",
            "64\n",
            "Valid loss: 0.4288049042224884\n",
            "Validation loss decreased\n",
            "65\n",
            "Valid loss: 0.42785897850990295\n",
            "Validation loss decreased\n",
            "66\n",
            "Valid loss: 0.4267546236515045\n",
            "Validation loss decreased\n",
            "67\n",
            "Valid loss: 0.4259386658668518\n",
            "Validation loss decreased\n",
            "68\n",
            "Valid loss: 0.42508646845817566\n",
            "Validation loss decreased\n",
            "69\n",
            "Valid loss: 0.42412394285202026\n",
            "Validation loss decreased\n",
            "70\n",
            "Valid loss: 0.42317086458206177\n",
            "Validation loss decreased\n",
            "71\n",
            "Valid loss: 0.42243775725364685\n",
            "Validation loss decreased\n",
            "72\n",
            "Valid loss: 0.42147859930992126\n",
            "Validation loss decreased\n",
            "73\n",
            "Valid loss: 0.42066752910614014\n",
            "Validation loss decreased\n",
            "74\n",
            "Valid loss: 0.419948011636734\n",
            "Validation loss decreased\n",
            "75\n",
            "Valid loss: 0.4192715585231781\n",
            "Validation loss decreased\n",
            "76\n",
            "Valid loss: 0.41859304904937744\n",
            "Validation loss decreased\n",
            "77\n",
            "Valid loss: 0.41798752546310425\n",
            "Validation loss decreased\n",
            "78\n",
            "Valid loss: 0.4172787368297577\n",
            "Validation loss decreased\n",
            "79\n",
            "Valid loss: 0.41662654280662537\n",
            "Validation loss decreased\n",
            "80\n",
            "Valid loss: 0.41600725054740906\n",
            "Validation loss decreased\n",
            "81\n",
            "Valid loss: 0.41549715399742126\n",
            "Validation loss decreased\n",
            "82\n",
            "Valid loss: 0.4147171676158905\n",
            "Validation loss decreased\n",
            "83\n",
            "Valid loss: 0.4141644239425659\n",
            "Validation loss decreased\n",
            "84\n",
            "Valid loss: 0.4137154519557953\n",
            "Validation loss decreased\n",
            "85\n",
            "Valid loss: 0.41340431571006775\n",
            "Validation loss decreased\n",
            "86\n",
            "Valid loss: 0.4127812683582306\n",
            "Validation loss decreased\n",
            "87\n",
            "Valid loss: 0.41234633326530457\n",
            "Validation loss decreased\n",
            "88\n",
            "Valid loss: 0.4117332100868225\n",
            "Validation loss decreased\n",
            "89\n",
            "Valid loss: 0.41131895780563354\n",
            "Validation loss decreased\n",
            "90\n",
            "Valid loss: 0.41099104285240173\n",
            "Validation loss decreased\n",
            "91\n",
            "Valid loss: 0.41047656536102295\n",
            "Validation loss decreased\n",
            "92\n",
            "Valid loss: 0.4100310504436493\n",
            "Validation loss decreased\n",
            "93\n",
            "Valid loss: 0.40970292687416077\n",
            "Validation loss decreased\n",
            "94\n",
            "Valid loss: 0.40943101048469543\n",
            "Validation loss decreased\n",
            "95\n",
            "Valid loss: 0.40904587507247925\n",
            "Validation loss decreased\n",
            "96\n",
            "Valid loss: 0.4087067246437073\n",
            "Validation loss decreased\n",
            "97\n",
            "Valid loss: 0.4084240198135376\n",
            "Validation loss decreased\n",
            "98\n",
            "Valid loss: 0.4080888628959656\n",
            "Validation loss decreased\n",
            "99\n",
            "Valid loss: 0.4077748656272888\n",
            "Validation loss decreased\n",
            "100\n",
            "Valid loss: 0.4075508415699005\n",
            "Validation loss decreased\n",
            "101\n",
            "Valid loss: 0.40732723474502563\n",
            "Validation loss decreased\n",
            "102\n",
            "Valid loss: 0.40695780515670776\n",
            "Validation loss decreased\n",
            "103\n",
            "Valid loss: 0.4068545699119568\n",
            "Validation loss decreased\n",
            "104\n",
            "Valid loss: 0.4066128432750702\n",
            "Validation loss decreased\n",
            "105\n",
            "Valid loss: 0.4063126742839813\n",
            "Validation loss decreased\n",
            "106\n",
            "Valid loss: 0.4060094654560089\n",
            "Validation loss decreased\n",
            "107\n",
            "Valid loss: 0.40591171383857727\n",
            "Validation loss decreased\n",
            "108\n",
            "Valid loss: 0.4057416021823883\n",
            "Validation loss decreased\n",
            "109\n",
            "Valid loss: 0.4055792987346649\n",
            "Validation loss decreased\n",
            "110\n",
            "Valid loss: 0.40529346466064453\n",
            "Validation loss decreased\n",
            "111\n",
            "Valid loss: 0.40531235933303833\n",
            "Validation loss did not improve. 1/50\n",
            "112\n",
            "Valid loss: 0.4051406979560852\n",
            "Validation loss decreased\n",
            "113\n",
            "Valid loss: 0.40508320927619934\n",
            "Validation loss decreased\n",
            "114\n",
            "Valid loss: 0.40486887097358704\n",
            "Validation loss decreased\n",
            "115\n",
            "Valid loss: 0.40474453568458557\n",
            "Validation loss decreased\n",
            "116\n",
            "Valid loss: 0.40468132495880127\n",
            "Validation loss decreased\n",
            "117\n",
            "Valid loss: 0.40464940667152405\n",
            "Validation loss decreased\n",
            "118\n",
            "Valid loss: 0.4045368432998657\n",
            "Validation loss decreased\n",
            "119\n",
            "Valid loss: 0.4041840434074402\n",
            "Validation loss decreased\n",
            "120\n",
            "Valid loss: 0.40410640835762024\n",
            "Validation loss decreased\n",
            "121\n",
            "Valid loss: 0.4038693308830261\n",
            "Validation loss decreased\n",
            "122\n",
            "Valid loss: 0.40372705459594727\n",
            "Validation loss decreased\n",
            "123\n",
            "Valid loss: 0.40365806221961975\n",
            "Validation loss decreased\n",
            "124\n",
            "Valid loss: 0.40373459458351135\n",
            "Validation loss did not improve. 1/50\n",
            "125\n",
            "Valid loss: 0.40359315276145935\n",
            "Validation loss decreased\n",
            "126\n",
            "Valid loss: 0.40339428186416626\n",
            "Validation loss decreased\n",
            "127\n",
            "Valid loss: 0.40332651138305664\n",
            "Validation loss decreased\n",
            "128\n",
            "Valid loss: 0.4032350182533264\n",
            "Validation loss decreased\n",
            "129\n",
            "Valid loss: 0.4030986726284027\n",
            "Validation loss decreased\n",
            "130\n",
            "Valid loss: 0.40286871790885925\n",
            "Validation loss decreased\n",
            "131\n",
            "Valid loss: 0.4027564823627472\n",
            "Validation loss decreased\n",
            "132\n",
            "Valid loss: 0.40266525745391846\n",
            "Validation loss decreased\n",
            "133\n",
            "Valid loss: 0.4025779068470001\n",
            "Validation loss decreased\n",
            "134\n",
            "Valid loss: 0.40260830521583557\n",
            "Validation loss did not improve. 1/50\n",
            "135\n",
            "Valid loss: 0.4025520980358124\n",
            "Validation loss decreased\n",
            "136\n",
            "Valid loss: 0.4026356637477875\n",
            "Validation loss did not improve. 1/50\n",
            "137\n",
            "Valid loss: 0.4024309515953064\n",
            "Validation loss decreased\n",
            "138\n",
            "Valid loss: 0.4024558961391449\n",
            "Validation loss did not improve. 1/50\n",
            "139\n",
            "Valid loss: 0.40242305397987366\n",
            "Validation loss decreased\n",
            "140\n",
            "Valid loss: 0.4023911654949188\n",
            "Validation loss decreased\n",
            "141\n",
            "Valid loss: 0.4021572768688202\n",
            "Validation loss decreased\n",
            "142\n",
            "Valid loss: 0.40214359760284424\n",
            "Validation loss decreased\n",
            "143\n",
            "Valid loss: 0.40201854705810547\n",
            "Validation loss decreased\n",
            "144\n",
            "Valid loss: 0.4018310010433197\n",
            "Validation loss decreased\n",
            "145\n",
            "Valid loss: 0.401750385761261\n",
            "Validation loss decreased\n",
            "146\n",
            "Valid loss: 0.4015914499759674\n",
            "Validation loss decreased\n",
            "147\n",
            "Valid loss: 0.4016128480434418\n",
            "Validation loss did not improve. 1/50\n",
            "148\n",
            "Valid loss: 0.4016784727573395\n",
            "Validation loss did not improve. 2/50\n",
            "149\n",
            "Valid loss: 0.40163055062294006\n",
            "Validation loss did not improve. 3/50\n",
            "150\n",
            "Valid loss: 0.40155452489852905\n",
            "Validation loss decreased\n",
            "151\n",
            "Valid loss: 0.4015226364135742\n",
            "Validation loss decreased\n",
            "152\n",
            "Valid loss: 0.40140387415885925\n",
            "Validation loss decreased\n",
            "153\n",
            "Valid loss: 0.40133413672447205\n",
            "Validation loss decreased\n",
            "154\n",
            "Valid loss: 0.40129712224006653\n",
            "Validation loss decreased\n",
            "155\n",
            "Valid loss: 0.4012099802494049\n",
            "Validation loss decreased\n",
            "156\n",
            "Valid loss: 0.40104562044143677\n",
            "Validation loss decreased\n",
            "157\n",
            "Valid loss: 0.40106672048568726\n",
            "Validation loss did not improve. 1/50\n",
            "158\n",
            "Valid loss: 0.40102246403694153\n",
            "Validation loss decreased\n",
            "159\n",
            "Valid loss: 0.40096840262413025\n",
            "Validation loss decreased\n",
            "160\n",
            "Valid loss: 0.4009954035282135\n",
            "Validation loss did not improve. 1/50\n",
            "161\n",
            "Valid loss: 0.40105965733528137\n",
            "Validation loss did not improve. 2/50\n",
            "162\n",
            "Valid loss: 0.4009415805339813\n",
            "Validation loss decreased\n",
            "163\n",
            "Valid loss: 0.4009341299533844\n",
            "Validation loss decreased\n",
            "164\n",
            "Valid loss: 0.40089190006256104\n",
            "Validation loss decreased\n",
            "165\n",
            "Valid loss: 0.40077975392341614\n",
            "Validation loss decreased\n",
            "166\n",
            "Valid loss: 0.4008466303348541\n",
            "Validation loss did not improve. 1/50\n",
            "167\n",
            "Valid loss: 0.4007180333137512\n",
            "Validation loss decreased\n",
            "168\n",
            "Valid loss: 0.4006887972354889\n",
            "Validation loss decreased\n",
            "169\n",
            "Valid loss: 0.4006357789039612\n",
            "Validation loss decreased\n",
            "170\n",
            "Valid loss: 0.4005337357521057\n",
            "Validation loss decreased\n",
            "171\n",
            "Valid loss: 0.40049102902412415\n",
            "Validation loss decreased\n",
            "172\n",
            "Valid loss: 0.40050074458122253\n",
            "Validation loss did not improve. 1/50\n",
            "173\n",
            "Valid loss: 0.4004555642604828\n",
            "Validation loss decreased\n",
            "174\n",
            "Valid loss: 0.4004930555820465\n",
            "Validation loss did not improve. 1/50\n",
            "175\n",
            "Valid loss: 0.40047696232795715\n",
            "Validation loss did not improve. 2/50\n",
            "176\n",
            "Valid loss: 0.40044334530830383\n",
            "Validation loss decreased\n",
            "177\n",
            "Valid loss: 0.40031373500823975\n",
            "Validation loss decreased\n",
            "178\n",
            "Valid loss: 0.4002922773361206\n",
            "Validation loss decreased\n",
            "179\n",
            "Valid loss: 0.40030157566070557\n",
            "Validation loss did not improve. 1/50\n",
            "180\n",
            "Valid loss: 0.4003077745437622\n",
            "Validation loss did not improve. 2/50\n",
            "181\n",
            "Valid loss: 0.4001942574977875\n",
            "Validation loss decreased\n",
            "182\n",
            "Valid loss: 0.400246798992157\n",
            "Validation loss did not improve. 1/50\n",
            "183\n",
            "Valid loss: 0.40007808804512024\n",
            "Validation loss decreased\n",
            "184\n",
            "Valid loss: 0.4000534415245056\n",
            "Validation loss decreased\n",
            "185\n",
            "Valid loss: 0.40005773305892944\n",
            "Validation loss did not improve. 1/50\n",
            "186\n",
            "Valid loss: 0.39998358488082886\n",
            "Validation loss decreased\n",
            "187\n",
            "Valid loss: 0.3999164402484894\n",
            "Validation loss decreased\n",
            "188\n",
            "Valid loss: 0.3999537229537964\n",
            "Validation loss did not improve. 1/50\n",
            "189\n",
            "Valid loss: 0.3999122381210327\n",
            "Validation loss decreased\n",
            "190\n",
            "Valid loss: 0.3998768627643585\n",
            "Validation loss decreased\n",
            "191\n",
            "Valid loss: 0.3999263644218445\n",
            "Validation loss did not improve. 1/50\n",
            "192\n",
            "Valid loss: 0.3998590409755707\n",
            "Validation loss decreased\n",
            "193\n",
            "Valid loss: 0.399664968252182\n",
            "Validation loss decreased\n",
            "194\n",
            "Valid loss: 0.3995935618877411\n",
            "Validation loss decreased\n",
            "195\n",
            "Valid loss: 0.399506151676178\n",
            "Validation loss decreased\n",
            "196\n",
            "Valid loss: 0.3994689881801605\n",
            "Validation loss decreased\n",
            "197\n",
            "Valid loss: 0.3995474874973297\n",
            "Validation loss did not improve. 1/50\n",
            "198\n",
            "Valid loss: 0.3994378447532654\n",
            "Validation loss decreased\n",
            "199\n",
            "Valid loss: 0.39941707253456116\n",
            "Validation loss decreased\n",
            "200\n",
            "Valid loss: 0.3993655741214752\n",
            "Validation loss decreased\n",
            "201\n",
            "Valid loss: 0.3992753028869629\n",
            "Validation loss decreased\n",
            "202\n",
            "Valid loss: 0.3992944359779358\n",
            "Validation loss did not improve. 1/50\n",
            "203\n",
            "Valid loss: 0.3992849886417389\n",
            "Validation loss did not improve. 2/50\n",
            "204\n",
            "Valid loss: 0.39923295378685\n",
            "Validation loss decreased\n",
            "205\n",
            "Valid loss: 0.39904505014419556\n",
            "Validation loss decreased\n",
            "206\n",
            "Valid loss: 0.399105966091156\n",
            "Validation loss did not improve. 1/50\n",
            "207\n",
            "Valid loss: 0.39904677867889404\n",
            "Validation loss did not improve. 2/50\n",
            "208\n",
            "Valid loss: 0.3989998996257782\n",
            "Validation loss decreased\n",
            "209\n",
            "Valid loss: 0.39877137541770935\n",
            "Validation loss decreased\n",
            "210\n",
            "Valid loss: 0.39874643087387085\n",
            "Validation loss decreased\n",
            "211\n",
            "Valid loss: 0.39867648482322693\n",
            "Validation loss decreased\n",
            "212\n",
            "Valid loss: 0.3986372649669647\n",
            "Validation loss decreased\n",
            "213\n",
            "Valid loss: 0.3986573815345764\n",
            "Validation loss did not improve. 1/50\n",
            "214\n",
            "Valid loss: 0.39861956238746643\n",
            "Validation loss decreased\n",
            "215\n",
            "Valid loss: 0.39855489134788513\n",
            "Validation loss decreased\n",
            "216\n",
            "Valid loss: 0.39858609437942505\n",
            "Validation loss did not improve. 1/50\n",
            "217\n",
            "Valid loss: 0.39839398860931396\n",
            "Validation loss decreased\n",
            "218\n",
            "Valid loss: 0.39834022521972656\n",
            "Validation loss decreased\n",
            "219\n",
            "Valid loss: 0.39832669496536255\n",
            "Validation loss decreased\n",
            "220\n",
            "Valid loss: 0.3982888460159302\n",
            "Validation loss decreased\n",
            "221\n",
            "Valid loss: 0.3981662690639496\n",
            "Validation loss decreased\n",
            "222\n",
            "Valid loss: 0.3982008695602417\n",
            "Validation loss did not improve. 1/50\n",
            "223\n",
            "Valid loss: 0.3982996940612793\n",
            "Validation loss did not improve. 2/50\n",
            "224\n",
            "Valid loss: 0.3982039988040924\n",
            "Validation loss did not improve. 3/50\n",
            "225\n",
            "Valid loss: 0.3981064260005951\n",
            "Validation loss decreased\n",
            "226\n",
            "Valid loss: 0.3980979323387146\n",
            "Validation loss decreased\n",
            "227\n",
            "Valid loss: 0.39798516035079956\n",
            "Validation loss decreased\n",
            "228\n",
            "Valid loss: 0.3979519307613373\n",
            "Validation loss decreased\n",
            "229\n",
            "Valid loss: 0.39796000719070435\n",
            "Validation loss did not improve. 1/50\n",
            "230\n",
            "Valid loss: 0.3978334069252014\n",
            "Validation loss decreased\n",
            "231\n",
            "Valid loss: 0.3978155255317688\n",
            "Validation loss decreased\n",
            "232\n",
            "Valid loss: 0.39775750041007996\n",
            "Validation loss decreased\n",
            "233\n",
            "Valid loss: 0.3976881802082062\n",
            "Validation loss decreased\n",
            "234\n",
            "Valid loss: 0.39776673913002014\n",
            "Validation loss did not improve. 1/50\n",
            "235\n",
            "Valid loss: 0.3978012502193451\n",
            "Validation loss did not improve. 2/50\n",
            "236\n",
            "Valid loss: 0.39774057269096375\n",
            "Validation loss did not improve. 3/50\n",
            "237\n",
            "Valid loss: 0.39774397015571594\n",
            "Validation loss did not improve. 4/50\n",
            "238\n",
            "Valid loss: 0.39761584997177124\n",
            "Validation loss decreased\n",
            "239\n",
            "Valid loss: 0.3976278603076935\n",
            "Validation loss did not improve. 1/50\n",
            "240\n",
            "Valid loss: 0.39751237630844116\n",
            "Validation loss decreased\n",
            "241\n",
            "Valid loss: 0.3974611461162567\n",
            "Validation loss decreased\n",
            "242\n",
            "Valid loss: 0.39723727107048035\n",
            "Validation loss decreased\n",
            "243\n",
            "Valid loss: 0.39707133173942566\n",
            "Validation loss decreased\n",
            "244\n",
            "Valid loss: 0.3971550762653351\n",
            "Validation loss did not improve. 1/50\n",
            "245\n",
            "Valid loss: 0.3969932198524475\n",
            "Validation loss decreased\n",
            "246\n",
            "Valid loss: 0.39698511362075806\n",
            "Validation loss decreased\n",
            "247\n",
            "Valid loss: 0.39703938364982605\n",
            "Validation loss did not improve. 1/50\n",
            "248\n",
            "Valid loss: 0.39702579379081726\n",
            "Validation loss did not improve. 2/50\n",
            "249\n",
            "Valid loss: 0.39688172936439514\n",
            "Validation loss decreased\n",
            "250\n",
            "Valid loss: 0.3968266248703003\n",
            "Validation loss decreased\n",
            "251\n",
            "Valid loss: 0.3968009352684021\n",
            "Validation loss decreased\n",
            "252\n",
            "Valid loss: 0.3967725932598114\n",
            "Validation loss decreased\n",
            "253\n",
            "Valid loss: 0.39674317836761475\n",
            "Validation loss decreased\n",
            "254\n",
            "Valid loss: 0.39673009514808655\n",
            "Validation loss decreased\n",
            "255\n",
            "Valid loss: 0.3966943621635437\n",
            "Validation loss decreased\n",
            "256\n",
            "Valid loss: 0.39677074551582336\n",
            "Validation loss did not improve. 1/50\n",
            "257\n",
            "Valid loss: 0.3966814875602722\n",
            "Validation loss decreased\n",
            "258\n",
            "Valid loss: 0.39666542410850525\n",
            "Validation loss decreased\n",
            "259\n",
            "Valid loss: 0.3965696096420288\n",
            "Validation loss decreased\n",
            "260\n",
            "Valid loss: 0.39654240012168884\n",
            "Validation loss decreased\n",
            "261\n",
            "Valid loss: 0.3964560925960541\n",
            "Validation loss decreased\n",
            "262\n",
            "Valid loss: 0.39643630385398865\n",
            "Validation loss decreased\n",
            "263\n",
            "Valid loss: 0.3963014483451843\n",
            "Validation loss decreased\n",
            "264\n",
            "Valid loss: 0.39637425541877747\n",
            "Validation loss did not improve. 1/50\n",
            "265\n",
            "Valid loss: 0.39636102318763733\n",
            "Validation loss did not improve. 2/50\n",
            "266\n",
            "Valid loss: 0.39636707305908203\n",
            "Validation loss did not improve. 3/50\n",
            "267\n",
            "Valid loss: 0.3963349759578705\n",
            "Validation loss did not improve. 4/50\n",
            "268\n",
            "Valid loss: 0.39633506536483765\n",
            "Validation loss did not improve. 5/50\n",
            "269\n",
            "Valid loss: 0.39624568819999695\n",
            "Validation loss decreased\n",
            "270\n",
            "Valid loss: 0.3962453007698059\n",
            "Validation loss decreased\n",
            "271\n",
            "Valid loss: 0.39613035321235657\n",
            "Validation loss decreased\n",
            "272\n",
            "Valid loss: 0.39603984355926514\n",
            "Validation loss decreased\n",
            "273\n",
            "Valid loss: 0.39602789282798767\n",
            "Validation loss decreased\n",
            "274\n",
            "Valid loss: 0.3959062993526459\n",
            "Validation loss decreased\n",
            "275\n",
            "Valid loss: 0.3957929015159607\n",
            "Validation loss decreased\n",
            "276\n",
            "Valid loss: 0.39588457345962524\n",
            "Validation loss did not improve. 1/50\n",
            "277\n",
            "Valid loss: 0.3958892226219177\n",
            "Validation loss did not improve. 2/50\n",
            "278\n",
            "Valid loss: 0.3959123194217682\n",
            "Validation loss did not improve. 3/50\n",
            "279\n",
            "Valid loss: 0.3958563804626465\n",
            "Validation loss did not improve. 4/50\n",
            "280\n",
            "Valid loss: 0.3959251940250397\n",
            "Validation loss did not improve. 5/50\n",
            "281\n",
            "Valid loss: 0.3959830701351166\n",
            "Validation loss did not improve. 6/50\n",
            "282\n",
            "Valid loss: 0.39581000804901123\n",
            "Validation loss did not improve. 7/50\n",
            "283\n",
            "Valid loss: 0.395764023065567\n",
            "Validation loss decreased\n",
            "284\n",
            "Valid loss: 0.39570263028144836\n",
            "Validation loss decreased\n",
            "285\n",
            "Valid loss: 0.3956712782382965\n",
            "Validation loss decreased\n",
            "286\n",
            "Valid loss: 0.39573848247528076\n",
            "Validation loss did not improve. 1/50\n",
            "287\n",
            "Valid loss: 0.3958149552345276\n",
            "Validation loss did not improve. 2/50\n",
            "288\n",
            "Valid loss: 0.3959362804889679\n",
            "Validation loss did not improve. 3/50\n",
            "289\n",
            "Valid loss: 0.39584842324256897\n",
            "Validation loss did not improve. 4/50\n",
            "290\n",
            "Valid loss: 0.3956947922706604\n",
            "Validation loss did not improve. 5/50\n",
            "291\n",
            "Valid loss: 0.39561018347740173\n",
            "Validation loss decreased\n",
            "292\n",
            "Valid loss: 0.39551955461502075\n",
            "Validation loss decreased\n",
            "293\n",
            "Valid loss: 0.39551717042922974\n",
            "Validation loss decreased\n",
            "294\n",
            "Valid loss: 0.39539843797683716\n",
            "Validation loss decreased\n",
            "295\n",
            "Valid loss: 0.39519885182380676\n",
            "Validation loss decreased\n",
            "296\n",
            "Valid loss: 0.3953297436237335\n",
            "Validation loss did not improve. 1/50\n",
            "297\n",
            "Valid loss: 0.3953269422054291\n",
            "Validation loss did not improve. 2/50\n",
            "298\n",
            "Valid loss: 0.3952038884162903\n",
            "Validation loss did not improve. 3/50\n",
            "299\n",
            "Valid loss: 0.39523428678512573\n",
            "Validation loss did not improve. 4/50\n",
            "300\n",
            "Valid loss: 0.3953225910663605\n",
            "Validation loss did not improve. 5/50\n",
            "301\n",
            "Valid loss: 0.3953325152397156\n",
            "Validation loss did not improve. 6/50\n",
            "302\n",
            "Valid loss: 0.39530906081199646\n",
            "Validation loss did not improve. 7/50\n",
            "303\n",
            "Valid loss: 0.39526093006134033\n",
            "Validation loss did not improve. 8/50\n",
            "304\n",
            "Valid loss: 0.39516109228134155\n",
            "Validation loss decreased\n",
            "305\n",
            "Valid loss: 0.39520853757858276\n",
            "Validation loss did not improve. 1/50\n",
            "306\n",
            "Valid loss: 0.3951604962348938\n",
            "Validation loss decreased\n",
            "307\n",
            "Valid loss: 0.39515921473503113\n",
            "Validation loss decreased\n",
            "308\n",
            "Valid loss: 0.39517849683761597\n",
            "Validation loss did not improve. 1/50\n",
            "309\n",
            "Valid loss: 0.39517852663993835\n",
            "Validation loss did not improve. 2/50\n",
            "310\n",
            "Valid loss: 0.3951031565666199\n",
            "Validation loss decreased\n",
            "311\n",
            "Valid loss: 0.3950222134590149\n",
            "Validation loss decreased\n",
            "312\n",
            "Valid loss: 0.395006000995636\n",
            "Validation loss decreased\n",
            "313\n",
            "Valid loss: 0.39485424757003784\n",
            "Validation loss decreased\n",
            "314\n",
            "Valid loss: 0.3947402238845825\n",
            "Validation loss decreased\n",
            "315\n",
            "Valid loss: 0.3946565091609955\n",
            "Validation loss decreased\n",
            "316\n",
            "Valid loss: 0.3945786654949188\n",
            "Validation loss decreased\n",
            "317\n",
            "Valid loss: 0.39456862211227417\n",
            "Validation loss decreased\n",
            "318\n",
            "Valid loss: 0.39456263184547424\n",
            "Validation loss decreased\n",
            "319\n",
            "Valid loss: 0.3945719003677368\n",
            "Validation loss did not improve. 1/50\n",
            "320\n",
            "Valid loss: 0.3946334421634674\n",
            "Validation loss did not improve. 2/50\n",
            "321\n",
            "Valid loss: 0.39455658197402954\n",
            "Validation loss decreased\n",
            "322\n",
            "Valid loss: 0.3944559097290039\n",
            "Validation loss decreased\n",
            "323\n",
            "Valid loss: 0.3945554494857788\n",
            "Validation loss did not improve. 1/50\n",
            "324\n",
            "Valid loss: 0.3944535553455353\n",
            "Validation loss decreased\n",
            "325\n",
            "Valid loss: 0.3944662809371948\n",
            "Validation loss did not improve. 1/50\n",
            "326\n",
            "Valid loss: 0.39433473348617554\n",
            "Validation loss decreased\n",
            "327\n",
            "Valid loss: 0.3941563367843628\n",
            "Validation loss decreased\n",
            "328\n",
            "Valid loss: 0.3941608667373657\n",
            "Validation loss did not improve. 1/50\n",
            "329\n",
            "Valid loss: 0.39416739344596863\n",
            "Validation loss did not improve. 2/50\n",
            "330\n",
            "Valid loss: 0.3940545320510864\n",
            "Validation loss decreased\n",
            "331\n",
            "Valid loss: 0.3940063416957855\n",
            "Validation loss decreased\n",
            "332\n",
            "Valid loss: 0.3940529525279999\n",
            "Validation loss did not improve. 1/50\n",
            "333\n",
            "Valid loss: 0.3939875364303589\n",
            "Validation loss decreased\n",
            "334\n",
            "Valid loss: 0.39393919706344604\n",
            "Validation loss decreased\n",
            "335\n",
            "Valid loss: 0.3938908576965332\n",
            "Validation loss decreased\n",
            "336\n",
            "Valid loss: 0.39385542273521423\n",
            "Validation loss decreased\n",
            "337\n",
            "Valid loss: 0.39376938343048096\n",
            "Validation loss decreased\n",
            "338\n",
            "Valid loss: 0.39375039935112\n",
            "Validation loss decreased\n",
            "339\n",
            "Valid loss: 0.3937431871891022\n",
            "Validation loss decreased\n",
            "340\n",
            "Valid loss: 0.39373454451560974\n",
            "Validation loss decreased\n",
            "341\n",
            "Valid loss: 0.3938879668712616\n",
            "Validation loss did not improve. 1/50\n",
            "342\n",
            "Valid loss: 0.3937549293041229\n",
            "Validation loss did not improve. 2/50\n",
            "343\n",
            "Valid loss: 0.3937727212905884\n",
            "Validation loss did not improve. 3/50\n",
            "344\n",
            "Valid loss: 0.39360475540161133\n",
            "Validation loss decreased\n",
            "345\n",
            "Valid loss: 0.39362651109695435\n",
            "Validation loss did not improve. 1/50\n",
            "346\n",
            "Valid loss: 0.3936404585838318\n",
            "Validation loss did not improve. 2/50\n",
            "347\n",
            "Valid loss: 0.39368757605552673\n",
            "Validation loss did not improve. 3/50\n",
            "348\n",
            "Valid loss: 0.39349421858787537\n",
            "Validation loss decreased\n",
            "349\n",
            "Valid loss: 0.39342573285102844\n",
            "Validation loss decreased\n",
            "350\n",
            "Valid loss: 0.39335107803344727\n",
            "Validation loss decreased\n",
            "351\n",
            "Valid loss: 0.393421471118927\n",
            "Validation loss did not improve. 1/50\n",
            "352\n",
            "Valid loss: 0.3933194875717163\n",
            "Validation loss decreased\n",
            "353\n",
            "Valid loss: 0.3933369219303131\n",
            "Validation loss did not improve. 1/50\n",
            "354\n",
            "Valid loss: 0.39333611726760864\n",
            "Validation loss did not improve. 2/50\n",
            "355\n",
            "Valid loss: 0.39312705397605896\n",
            "Validation loss decreased\n",
            "356\n",
            "Valid loss: 0.3930491507053375\n",
            "Validation loss decreased\n",
            "357\n",
            "Valid loss: 0.3929971754550934\n",
            "Validation loss decreased\n",
            "358\n",
            "Valid loss: 0.3929884731769562\n",
            "Validation loss decreased\n",
            "359\n",
            "Valid loss: 0.39300358295440674\n",
            "Validation loss did not improve. 1/50\n",
            "360\n",
            "Valid loss: 0.3929518163204193\n",
            "Validation loss decreased\n",
            "361\n",
            "Valid loss: 0.3928990364074707\n",
            "Validation loss decreased\n",
            "362\n",
            "Valid loss: 0.39293476939201355\n",
            "Validation loss did not improve. 1/50\n",
            "363\n",
            "Valid loss: 0.39284369349479675\n",
            "Validation loss decreased\n",
            "364\n",
            "Valid loss: 0.3926258981227875\n",
            "Validation loss decreased\n",
            "365\n",
            "Valid loss: 0.3926321566104889\n",
            "Validation loss did not improve. 1/50\n",
            "366\n",
            "Valid loss: 0.3927600085735321\n",
            "Validation loss did not improve. 2/50\n",
            "367\n",
            "Valid loss: 0.39268210530281067\n",
            "Validation loss did not improve. 3/50\n",
            "368\n",
            "Valid loss: 0.3927535116672516\n",
            "Validation loss did not improve. 4/50\n",
            "369\n",
            "Valid loss: 0.3926902115345001\n",
            "Validation loss did not improve. 5/50\n",
            "370\n",
            "Valid loss: 0.39265021681785583\n",
            "Validation loss did not improve. 6/50\n",
            "371\n",
            "Valid loss: 0.39263248443603516\n",
            "Validation loss did not improve. 7/50\n",
            "372\n",
            "Valid loss: 0.3925814628601074\n",
            "Validation loss decreased\n",
            "373\n",
            "Valid loss: 0.39250269532203674\n",
            "Validation loss decreased\n",
            "374\n",
            "Valid loss: 0.39258161187171936\n",
            "Validation loss did not improve. 1/50\n",
            "375\n",
            "Valid loss: 0.39250215888023376\n",
            "Validation loss decreased\n",
            "376\n",
            "Valid loss: 0.39245328307151794\n",
            "Validation loss decreased\n",
            "377\n",
            "Valid loss: 0.39233800768852234\n",
            "Validation loss decreased\n",
            "378\n",
            "Valid loss: 0.3922589123249054\n",
            "Validation loss decreased\n",
            "379\n",
            "Valid loss: 0.39231425523757935\n",
            "Validation loss did not improve. 1/50\n",
            "380\n",
            "Valid loss: 0.39208099246025085\n",
            "Validation loss decreased\n",
            "381\n",
            "Valid loss: 0.3919970691204071\n",
            "Validation loss decreased\n",
            "382\n",
            "Valid loss: 0.39205849170684814\n",
            "Validation loss did not improve. 1/50\n",
            "383\n",
            "Valid loss: 0.3920062482357025\n",
            "Validation loss did not improve. 2/50\n",
            "384\n",
            "Valid loss: 0.39187660813331604\n",
            "Validation loss decreased\n",
            "385\n",
            "Valid loss: 0.3918602764606476\n",
            "Validation loss decreased\n",
            "386\n",
            "Valid loss: 0.3919616639614105\n",
            "Validation loss did not improve. 1/50\n",
            "387\n",
            "Valid loss: 0.3917659521102905\n",
            "Validation loss decreased\n",
            "388\n",
            "Valid loss: 0.3917883038520813\n",
            "Validation loss did not improve. 1/50\n",
            "389\n",
            "Valid loss: 0.39174872636795044\n",
            "Validation loss decreased\n",
            "390\n",
            "Valid loss: 0.3917101323604584\n",
            "Validation loss decreased\n",
            "391\n",
            "Valid loss: 0.3918207287788391\n",
            "Validation loss did not improve. 1/50\n",
            "392\n",
            "Valid loss: 0.3917597830295563\n",
            "Validation loss did not improve. 2/50\n",
            "393\n",
            "Valid loss: 0.39161044359207153\n",
            "Validation loss decreased\n",
            "394\n",
            "Valid loss: 0.39158013463020325\n",
            "Validation loss decreased\n",
            "395\n",
            "Valid loss: 0.39150673151016235\n",
            "Validation loss decreased\n",
            "396\n",
            "Valid loss: 0.39146754145622253\n",
            "Validation loss decreased\n",
            "397\n",
            "Valid loss: 0.39142540097236633\n",
            "Validation loss decreased\n",
            "398\n",
            "Valid loss: 0.39134737849235535\n",
            "Validation loss decreased\n",
            "399\n",
            "Valid loss: 0.391357958316803\n",
            "Validation loss did not improve. 1/50\n",
            "400\n",
            "Valid loss: 0.39128655195236206\n",
            "Validation loss decreased\n",
            "401\n",
            "Valid loss: 0.39131659269332886\n",
            "Validation loss did not improve. 1/50\n",
            "402\n",
            "Valid loss: 0.39131516218185425\n",
            "Validation loss did not improve. 2/50\n",
            "403\n",
            "Valid loss: 0.39136525988578796\n",
            "Validation loss did not improve. 3/50\n",
            "404\n",
            "Valid loss: 0.3913554847240448\n",
            "Validation loss did not improve. 4/50\n",
            "405\n",
            "Valid loss: 0.39127784967422485\n",
            "Validation loss decreased\n",
            "406\n",
            "Valid loss: 0.3912598192691803\n",
            "Validation loss decreased\n",
            "407\n",
            "Valid loss: 0.3911241590976715\n",
            "Validation loss decreased\n",
            "408\n",
            "Valid loss: 0.3909819722175598\n",
            "Validation loss decreased\n",
            "409\n",
            "Valid loss: 0.39086654782295227\n",
            "Validation loss decreased\n",
            "410\n",
            "Valid loss: 0.39086952805519104\n",
            "Validation loss did not improve. 1/50\n",
            "411\n",
            "Valid loss: 0.39079731702804565\n",
            "Validation loss decreased\n",
            "412\n",
            "Valid loss: 0.39077797532081604\n",
            "Validation loss decreased\n",
            "413\n",
            "Valid loss: 0.3909047544002533\n",
            "Validation loss did not improve. 1/50\n",
            "414\n",
            "Valid loss: 0.3908330798149109\n",
            "Validation loss did not improve. 2/50\n",
            "415\n",
            "Valid loss: 0.3907480835914612\n",
            "Validation loss decreased\n",
            "416\n",
            "Valid loss: 0.39079543948173523\n",
            "Validation loss did not improve. 1/50\n",
            "417\n",
            "Valid loss: 0.39068803191185\n",
            "Validation loss decreased\n",
            "418\n",
            "Valid loss: 0.39076462388038635\n",
            "Validation loss did not improve. 1/50\n",
            "419\n",
            "Valid loss: 0.39077746868133545\n",
            "Validation loss did not improve. 2/50\n",
            "420\n",
            "Valid loss: 0.39066436886787415\n",
            "Validation loss decreased\n",
            "421\n",
            "Valid loss: 0.390631765127182\n",
            "Validation loss decreased\n",
            "422\n",
            "Valid loss: 0.39056211709976196\n",
            "Validation loss decreased\n",
            "423\n",
            "Valid loss: 0.3904295563697815\n",
            "Validation loss decreased\n",
            "424\n",
            "Valid loss: 0.3904300332069397\n",
            "Validation loss did not improve. 1/50\n",
            "425\n",
            "Valid loss: 0.39038974046707153\n",
            "Validation loss decreased\n",
            "426\n",
            "Valid loss: 0.3903732895851135\n",
            "Validation loss decreased\n",
            "427\n",
            "Valid loss: 0.3903369903564453\n",
            "Validation loss decreased\n",
            "428\n",
            "Valid loss: 0.3902999460697174\n",
            "Validation loss decreased\n",
            "429\n",
            "Valid loss: 0.3903018534183502\n",
            "Validation loss did not improve. 1/50\n",
            "430\n",
            "Valid loss: 0.39023247361183167\n",
            "Validation loss decreased\n",
            "431\n",
            "Valid loss: 0.3901675045490265\n",
            "Validation loss decreased\n",
            "432\n",
            "Valid loss: 0.390040785074234\n",
            "Validation loss decreased\n",
            "433\n",
            "Valid loss: 0.3900057375431061\n",
            "Validation loss decreased\n",
            "434\n",
            "Valid loss: 0.3899666965007782\n",
            "Validation loss decreased\n",
            "435\n",
            "Valid loss: 0.38990452885627747\n",
            "Validation loss decreased\n",
            "436\n",
            "Valid loss: 0.38988521695137024\n",
            "Validation loss decreased\n",
            "437\n",
            "Valid loss: 0.3899058401584625\n",
            "Validation loss did not improve. 1/50\n",
            "438\n",
            "Valid loss: 0.3899087905883789\n",
            "Validation loss did not improve. 2/50\n",
            "439\n",
            "Valid loss: 0.3900079131126404\n",
            "Validation loss did not improve. 3/50\n",
            "440\n",
            "Valid loss: 0.38976433873176575\n",
            "Validation loss decreased\n",
            "441\n",
            "Valid loss: 0.38980579376220703\n",
            "Validation loss did not improve. 1/50\n",
            "442\n",
            "Valid loss: 0.3898142874240875\n",
            "Validation loss did not improve. 2/50\n",
            "443\n",
            "Valid loss: 0.3897753953933716\n",
            "Validation loss did not improve. 3/50\n",
            "444\n",
            "Valid loss: 0.3898182809352875\n",
            "Validation loss did not improve. 4/50\n",
            "445\n",
            "Valid loss: 0.38994255661964417\n",
            "Validation loss did not improve. 5/50\n",
            "446\n",
            "Valid loss: 0.38982757925987244\n",
            "Validation loss did not improve. 6/50\n",
            "447\n",
            "Valid loss: 0.38982051610946655\n",
            "Validation loss did not improve. 7/50\n",
            "448\n",
            "Valid loss: 0.38978105783462524\n",
            "Validation loss did not improve. 8/50\n",
            "449\n",
            "Valid loss: 0.3897208869457245\n",
            "Validation loss decreased\n",
            "450\n",
            "Valid loss: 0.3896501660346985\n",
            "Validation loss decreased\n",
            "451\n",
            "Valid loss: 0.3896177411079407\n",
            "Validation loss decreased\n",
            "452\n",
            "Valid loss: 0.38959941267967224\n",
            "Validation loss decreased\n",
            "453\n",
            "Valid loss: 0.3894987106323242\n",
            "Validation loss decreased\n",
            "454\n",
            "Valid loss: 0.3896135985851288\n",
            "Validation loss did not improve. 1/50\n",
            "455\n",
            "Valid loss: 0.38956186175346375\n",
            "Validation loss did not improve. 2/50\n",
            "456\n",
            "Valid loss: 0.38943207263946533\n",
            "Validation loss decreased\n",
            "457\n",
            "Valid loss: 0.38939979672431946\n",
            "Validation loss decreased\n",
            "458\n",
            "Valid loss: 0.389523983001709\n",
            "Validation loss did not improve. 1/50\n",
            "459\n",
            "Valid loss: 0.3894929587841034\n",
            "Validation loss did not improve. 2/50\n",
            "460\n",
            "Valid loss: 0.38941600918769836\n",
            "Validation loss did not improve. 3/50\n",
            "461\n",
            "Valid loss: 0.3894939720630646\n",
            "Validation loss did not improve. 4/50\n",
            "462\n",
            "Valid loss: 0.3893111050128937\n",
            "Validation loss decreased\n",
            "463\n",
            "Valid loss: 0.3893074095249176\n",
            "Validation loss decreased\n",
            "464\n",
            "Valid loss: 0.3893154263496399\n",
            "Validation loss did not improve. 1/50\n",
            "465\n",
            "Valid loss: 0.38923853635787964\n",
            "Validation loss decreased\n",
            "466\n",
            "Valid loss: 0.38922303915023804\n",
            "Validation loss decreased\n",
            "467\n",
            "Valid loss: 0.38919275999069214\n",
            "Validation loss decreased\n",
            "468\n",
            "Valid loss: 0.38921818137168884\n",
            "Validation loss did not improve. 1/50\n",
            "469\n",
            "Valid loss: 0.3892784118652344\n",
            "Validation loss did not improve. 2/50\n",
            "470\n",
            "Valid loss: 0.38923248648643494\n",
            "Validation loss did not improve. 3/50\n",
            "471\n",
            "Valid loss: 0.3891209363937378\n",
            "Validation loss decreased\n",
            "472\n",
            "Valid loss: 0.38920193910598755\n",
            "Validation loss did not improve. 1/50\n",
            "473\n",
            "Valid loss: 0.3891729414463043\n",
            "Validation loss did not improve. 2/50\n",
            "474\n",
            "Valid loss: 0.3892861306667328\n",
            "Validation loss did not improve. 3/50\n",
            "475\n",
            "Valid loss: 0.38922083377838135\n",
            "Validation loss did not improve. 4/50\n",
            "476\n",
            "Valid loss: 0.38917890191078186\n",
            "Validation loss did not improve. 5/50\n",
            "477\n",
            "Valid loss: 0.3891080617904663\n",
            "Validation loss decreased\n",
            "478\n",
            "Valid loss: 0.3889705240726471\n",
            "Validation loss decreased\n",
            "479\n",
            "Valid loss: 0.38891443610191345\n",
            "Validation loss decreased\n",
            "480\n",
            "Valid loss: 0.3888886570930481\n",
            "Validation loss decreased\n",
            "481\n",
            "Valid loss: 0.38885873556137085\n",
            "Validation loss decreased\n",
            "482\n",
            "Valid loss: 0.3887341320514679\n",
            "Validation loss decreased\n",
            "483\n",
            "Valid loss: 0.3887515962123871\n",
            "Validation loss did not improve. 1/50\n",
            "484\n",
            "Valid loss: 0.3887685537338257\n",
            "Validation loss did not improve. 2/50\n",
            "485\n",
            "Valid loss: 0.38888370990753174\n",
            "Validation loss did not improve. 3/50\n",
            "486\n",
            "Valid loss: 0.38892582058906555\n",
            "Validation loss did not improve. 4/50\n",
            "487\n",
            "Valid loss: 0.3889683187007904\n",
            "Validation loss did not improve. 5/50\n",
            "488\n",
            "Valid loss: 0.3888527452945709\n",
            "Validation loss did not improve. 6/50\n",
            "489\n",
            "Valid loss: 0.38878747820854187\n",
            "Validation loss did not improve. 7/50\n",
            "490\n",
            "Valid loss: 0.3887880742549896\n",
            "Validation loss did not improve. 8/50\n",
            "491\n",
            "Valid loss: 0.38877665996551514\n",
            "Validation loss did not improve. 9/50\n",
            "492\n",
            "Valid loss: 0.38883474469184875\n",
            "Validation loss did not improve. 10/50\n",
            "493\n",
            "Valid loss: 0.38880035281181335\n",
            "Validation loss did not improve. 11/50\n",
            "494\n",
            "Valid loss: 0.38865914940834045\n",
            "Validation loss decreased\n",
            "495\n",
            "Valid loss: 0.3886111080646515\n",
            "Validation loss decreased\n",
            "496\n",
            "Valid loss: 0.3886382281780243\n",
            "Validation loss did not improve. 1/50\n",
            "497\n",
            "Valid loss: 0.38853269815444946\n",
            "Validation loss decreased\n",
            "498\n",
            "Valid loss: 0.38845282793045044\n",
            "Validation loss decreased\n",
            "499\n",
            "Valid loss: 0.3884166479110718\n",
            "Validation loss decreased\n",
            "500\n",
            "Valid loss: 0.38832223415374756\n",
            "Validation loss decreased\n",
            "501\n",
            "Valid loss: 0.38832366466522217\n",
            "Validation loss did not improve. 1/50\n",
            "502\n",
            "Valid loss: 0.3884133994579315\n",
            "Validation loss did not improve. 2/50\n",
            "503\n",
            "Valid loss: 0.3883073925971985\n",
            "Validation loss decreased\n",
            "504\n",
            "Valid loss: 0.38831380009651184\n",
            "Validation loss did not improve. 1/50\n",
            "505\n",
            "Valid loss: 0.38832396268844604\n",
            "Validation loss did not improve. 2/50\n",
            "506\n",
            "Valid loss: 0.3881981670856476\n",
            "Validation loss decreased\n",
            "507\n",
            "Valid loss: 0.3881276547908783\n",
            "Validation loss decreased\n",
            "508\n",
            "Valid loss: 0.38804322481155396\n",
            "Validation loss decreased\n",
            "509\n",
            "Valid loss: 0.3880752623081207\n",
            "Validation loss did not improve. 1/50\n",
            "510\n",
            "Valid loss: 0.3881465792655945\n",
            "Validation loss did not improve. 2/50\n",
            "511\n",
            "Valid loss: 0.3880840837955475\n",
            "Validation loss did not improve. 3/50\n",
            "512\n",
            "Valid loss: 0.3880564868450165\n",
            "Validation loss did not improve. 4/50\n",
            "513\n",
            "Valid loss: 0.3881324231624603\n",
            "Validation loss did not improve. 5/50\n",
            "514\n",
            "Valid loss: 0.3881602883338928\n",
            "Validation loss did not improve. 6/50\n",
            "515\n",
            "Valid loss: 0.3882642686367035\n",
            "Validation loss did not improve. 7/50\n",
            "516\n",
            "Valid loss: 0.38815590739250183\n",
            "Validation loss did not improve. 8/50\n",
            "517\n",
            "Valid loss: 0.3880290687084198\n",
            "Validation loss decreased\n",
            "518\n",
            "Valid loss: 0.3881293833255768\n",
            "Validation loss did not improve. 1/50\n",
            "519\n",
            "Valid loss: 0.3881015181541443\n",
            "Validation loss did not improve. 2/50\n",
            "520\n",
            "Valid loss: 0.3880435824394226\n",
            "Validation loss did not improve. 3/50\n",
            "521\n",
            "Valid loss: 0.38815122842788696\n",
            "Validation loss did not improve. 4/50\n",
            "522\n",
            "Valid loss: 0.38804376125335693\n",
            "Validation loss did not improve. 5/50\n",
            "523\n",
            "Valid loss: 0.3879134953022003\n",
            "Validation loss decreased\n",
            "524\n",
            "Valid loss: 0.38782960176467896\n",
            "Validation loss decreased\n",
            "525\n",
            "Valid loss: 0.38781946897506714\n",
            "Validation loss decreased\n",
            "526\n",
            "Valid loss: 0.3877581059932709\n",
            "Validation loss decreased\n",
            "527\n",
            "Valid loss: 0.38786181807518005\n",
            "Validation loss did not improve. 1/50\n",
            "528\n",
            "Valid loss: 0.38777533173561096\n",
            "Validation loss did not improve. 2/50\n",
            "529\n",
            "Valid loss: 0.3877229690551758\n",
            "Validation loss decreased\n",
            "530\n",
            "Valid loss: 0.38772234320640564\n",
            "Validation loss decreased\n",
            "531\n",
            "Valid loss: 0.3877497613430023\n",
            "Validation loss did not improve. 1/50\n",
            "532\n",
            "Valid loss: 0.38764867186546326\n",
            "Validation loss decreased\n",
            "533\n",
            "Valid loss: 0.3875804841518402\n",
            "Validation loss decreased\n",
            "534\n",
            "Valid loss: 0.38758718967437744\n",
            "Validation loss did not improve. 1/50\n",
            "535\n",
            "Valid loss: 0.38757023215293884\n",
            "Validation loss decreased\n",
            "536\n",
            "Valid loss: 0.3875883221626282\n",
            "Validation loss did not improve. 1/50\n",
            "537\n",
            "Valid loss: 0.38766345381736755\n",
            "Validation loss did not improve. 2/50\n",
            "538\n",
            "Valid loss: 0.3875839114189148\n",
            "Validation loss did not improve. 3/50\n",
            "539\n",
            "Valid loss: 0.38759076595306396\n",
            "Validation loss did not improve. 4/50\n",
            "540\n",
            "Valid loss: 0.3875947594642639\n",
            "Validation loss did not improve. 5/50\n",
            "541\n",
            "Valid loss: 0.3876178562641144\n",
            "Validation loss did not improve. 6/50\n",
            "542\n",
            "Valid loss: 0.3875662684440613\n",
            "Validation loss decreased\n",
            "543\n",
            "Valid loss: 0.38749369978904724\n",
            "Validation loss decreased\n",
            "544\n",
            "Valid loss: 0.38740062713623047\n",
            "Validation loss decreased\n",
            "545\n",
            "Valid loss: 0.3874097764492035\n",
            "Validation loss did not improve. 1/50\n",
            "546\n",
            "Valid loss: 0.3873675465583801\n",
            "Validation loss decreased\n",
            "547\n",
            "Valid loss: 0.38729026913642883\n",
            "Validation loss decreased\n",
            "548\n",
            "Valid loss: 0.38735973834991455\n",
            "Validation loss did not improve. 1/50\n",
            "549\n",
            "Valid loss: 0.38731610774993896\n",
            "Validation loss did not improve. 2/50\n",
            "550\n",
            "Valid loss: 0.3874303996562958\n",
            "Validation loss did not improve. 3/50\n",
            "551\n",
            "Valid loss: 0.3873896896839142\n",
            "Validation loss did not improve. 4/50\n",
            "552\n",
            "Valid loss: 0.38734865188598633\n",
            "Validation loss did not improve. 5/50\n",
            "553\n",
            "Valid loss: 0.3873644173145294\n",
            "Validation loss did not improve. 6/50\n",
            "554\n",
            "Valid loss: 0.3872300982475281\n",
            "Validation loss decreased\n",
            "555\n",
            "Valid loss: 0.38718175888061523\n",
            "Validation loss decreased\n",
            "556\n",
            "Valid loss: 0.3871704339981079\n",
            "Validation loss decreased\n",
            "557\n",
            "Valid loss: 0.3871268630027771\n",
            "Validation loss decreased\n",
            "558\n",
            "Valid loss: 0.3870816230773926\n",
            "Validation loss decreased\n",
            "559\n",
            "Valid loss: 0.3869847059249878\n",
            "Validation loss decreased\n",
            "560\n",
            "Valid loss: 0.3869648277759552\n",
            "Validation loss decreased\n",
            "561\n",
            "Valid loss: 0.386976420879364\n",
            "Validation loss did not improve. 1/50\n",
            "562\n",
            "Valid loss: 0.3869342803955078\n",
            "Validation loss decreased\n",
            "563\n",
            "Valid loss: 0.3870198428630829\n",
            "Validation loss did not improve. 1/50\n",
            "564\n",
            "Valid loss: 0.3870081901550293\n",
            "Validation loss did not improve. 2/50\n",
            "565\n",
            "Valid loss: 0.3869261145591736\n",
            "Validation loss decreased\n",
            "566\n",
            "Valid loss: 0.38693347573280334\n",
            "Validation loss did not improve. 1/50\n",
            "567\n",
            "Valid loss: 0.38699257373809814\n",
            "Validation loss did not improve. 2/50\n",
            "568\n",
            "Valid loss: 0.3868553936481476\n",
            "Validation loss decreased\n",
            "569\n",
            "Valid loss: 0.3867720663547516\n",
            "Validation loss decreased\n",
            "570\n",
            "Valid loss: 0.3867667019367218\n",
            "Validation loss decreased\n",
            "571\n",
            "Valid loss: 0.38676613569259644\n",
            "Validation loss decreased\n",
            "572\n",
            "Valid loss: 0.3867574632167816\n",
            "Validation loss decreased\n",
            "573\n",
            "Valid loss: 0.3866978585720062\n",
            "Validation loss decreased\n",
            "574\n",
            "Valid loss: 0.38665440678596497\n",
            "Validation loss decreased\n",
            "575\n",
            "Valid loss: 0.3866952359676361\n",
            "Validation loss did not improve. 1/50\n",
            "576\n",
            "Valid loss: 0.38668230175971985\n",
            "Validation loss did not improve. 2/50\n",
            "577\n",
            "Valid loss: 0.38671809434890747\n",
            "Validation loss did not improve. 3/50\n",
            "578\n",
            "Valid loss: 0.3866536319255829\n",
            "Validation loss decreased\n",
            "579\n",
            "Valid loss: 0.38673800230026245\n",
            "Validation loss did not improve. 1/50\n",
            "580\n",
            "Valid loss: 0.3866378366947174\n",
            "Validation loss decreased\n",
            "581\n",
            "Valid loss: 0.3865451216697693\n",
            "Validation loss decreased\n",
            "582\n",
            "Valid loss: 0.3865010142326355\n",
            "Validation loss decreased\n",
            "583\n",
            "Valid loss: 0.386476069688797\n",
            "Validation loss decreased\n",
            "584\n",
            "Valid loss: 0.38648730516433716\n",
            "Validation loss did not improve. 1/50\n",
            "585\n",
            "Valid loss: 0.3864375948905945\n",
            "Validation loss decreased\n",
            "586\n",
            "Valid loss: 0.38656312227249146\n",
            "Validation loss did not improve. 1/50\n",
            "587\n",
            "Valid loss: 0.3864629864692688\n",
            "Validation loss did not improve. 2/50\n",
            "588\n",
            "Valid loss: 0.38654258847236633\n",
            "Validation loss did not improve. 3/50\n",
            "589\n",
            "Valid loss: 0.3865605890750885\n",
            "Validation loss did not improve. 4/50\n",
            "590\n",
            "Valid loss: 0.38647642731666565\n",
            "Validation loss did not improve. 5/50\n",
            "591\n",
            "Valid loss: 0.38663235306739807\n",
            "Validation loss did not improve. 6/50\n",
            "592\n",
            "Valid loss: 0.386513352394104\n",
            "Validation loss did not improve. 7/50\n",
            "593\n",
            "Valid loss: 0.38643673062324524\n",
            "Validation loss decreased\n",
            "594\n",
            "Valid loss: 0.3864334523677826\n",
            "Validation loss decreased\n",
            "595\n",
            "Valid loss: 0.38652312755584717\n",
            "Validation loss did not improve. 1/50\n",
            "596\n",
            "Valid loss: 0.38638636469841003\n",
            "Validation loss decreased\n",
            "597\n",
            "Valid loss: 0.3863815665245056\n",
            "Validation loss decreased\n",
            "598\n",
            "Valid loss: 0.3862629234790802\n",
            "Validation loss decreased\n",
            "599\n",
            "Valid loss: 0.38628244400024414\n",
            "Validation loss did not improve. 1/50\n",
            "600\n",
            "Valid loss: 0.38636842370033264\n",
            "Validation loss did not improve. 2/50\n",
            "601\n",
            "Valid loss: 0.38631969690322876\n",
            "Validation loss did not improve. 3/50\n",
            "602\n",
            "Valid loss: 0.38625967502593994\n",
            "Validation loss decreased\n",
            "603\n",
            "Valid loss: 0.3863118886947632\n",
            "Validation loss did not improve. 1/50\n",
            "604\n",
            "Valid loss: 0.3863946795463562\n",
            "Validation loss did not improve. 2/50\n",
            "605\n",
            "Valid loss: 0.3863660395145416\n",
            "Validation loss did not improve. 3/50\n",
            "606\n",
            "Valid loss: 0.3862536549568176\n",
            "Validation loss decreased\n",
            "607\n",
            "Valid loss: 0.38618966937065125\n",
            "Validation loss decreased\n",
            "608\n",
            "Valid loss: 0.38617026805877686\n",
            "Validation loss decreased\n",
            "609\n",
            "Valid loss: 0.3861297070980072\n",
            "Validation loss decreased\n",
            "610\n",
            "Valid loss: 0.38601887226104736\n",
            "Validation loss decreased\n",
            "611\n",
            "Valid loss: 0.3861047625541687\n",
            "Validation loss did not improve. 1/50\n",
            "612\n",
            "Valid loss: 0.3861624002456665\n",
            "Validation loss did not improve. 2/50\n",
            "613\n",
            "Valid loss: 0.38602930307388306\n",
            "Validation loss did not improve. 3/50\n",
            "614\n",
            "Valid loss: 0.38612061738967896\n",
            "Validation loss did not improve. 4/50\n",
            "615\n",
            "Valid loss: 0.38611385226249695\n",
            "Validation loss did not improve. 5/50\n",
            "616\n",
            "Valid loss: 0.38624465465545654\n",
            "Validation loss did not improve. 6/50\n",
            "617\n",
            "Valid loss: 0.3860737979412079\n",
            "Validation loss did not improve. 7/50\n",
            "618\n",
            "Valid loss: 0.38604652881622314\n",
            "Validation loss did not improve. 8/50\n",
            "619\n",
            "Valid loss: 0.38616302609443665\n",
            "Validation loss did not improve. 9/50\n",
            "620\n",
            "Valid loss: 0.3861736059188843\n",
            "Validation loss did not improve. 10/50\n",
            "621\n",
            "Valid loss: 0.386243999004364\n",
            "Validation loss did not improve. 11/50\n",
            "622\n",
            "Valid loss: 0.38622844219207764\n",
            "Validation loss did not improve. 12/50\n",
            "623\n",
            "Valid loss: 0.3861708343029022\n",
            "Validation loss did not improve. 13/50\n",
            "624\n",
            "Valid loss: 0.3861370384693146\n",
            "Validation loss did not improve. 14/50\n",
            "625\n",
            "Valid loss: 0.38608840107917786\n",
            "Validation loss did not improve. 15/50\n",
            "626\n",
            "Valid loss: 0.38610202074050903\n",
            "Validation loss did not improve. 16/50\n",
            "627\n",
            "Valid loss: 0.3860999643802643\n",
            "Validation loss did not improve. 17/50\n",
            "628\n",
            "Valid loss: 0.38599008321762085\n",
            "Validation loss decreased\n",
            "629\n",
            "Valid loss: 0.3859536051750183\n",
            "Validation loss decreased\n",
            "630\n",
            "Valid loss: 0.3859749734401703\n",
            "Validation loss did not improve. 1/50\n",
            "631\n",
            "Valid loss: 0.38595226407051086\n",
            "Validation loss decreased\n",
            "632\n",
            "Valid loss: 0.3858834207057953\n",
            "Validation loss decreased\n",
            "633\n",
            "Valid loss: 0.38596460223197937\n",
            "Validation loss did not improve. 1/50\n",
            "634\n",
            "Valid loss: 0.3858749568462372\n",
            "Validation loss decreased\n",
            "635\n",
            "Valid loss: 0.38585567474365234\n",
            "Validation loss decreased\n",
            "636\n",
            "Valid loss: 0.38578444719314575\n",
            "Validation loss decreased\n",
            "637\n",
            "Valid loss: 0.3858061730861664\n",
            "Validation loss did not improve. 1/50\n",
            "638\n",
            "Valid loss: 0.38572630286216736\n",
            "Validation loss decreased\n",
            "639\n",
            "Valid loss: 0.3855976462364197\n",
            "Validation loss decreased\n",
            "640\n",
            "Valid loss: 0.3856085538864136\n",
            "Validation loss did not improve. 1/50\n",
            "641\n",
            "Valid loss: 0.3855871260166168\n",
            "Validation loss decreased\n",
            "642\n",
            "Valid loss: 0.38566330075263977\n",
            "Validation loss did not improve. 1/50\n",
            "643\n",
            "Valid loss: 0.3857420086860657\n",
            "Validation loss did not improve. 2/50\n",
            "644\n",
            "Valid loss: 0.3856717646121979\n",
            "Validation loss did not improve. 3/50\n",
            "645\n",
            "Valid loss: 0.3857804536819458\n",
            "Validation loss did not improve. 4/50\n",
            "646\n",
            "Valid loss: 0.38571256399154663\n",
            "Validation loss did not improve. 5/50\n",
            "647\n",
            "Valid loss: 0.38567957282066345\n",
            "Validation loss did not improve. 6/50\n",
            "648\n",
            "Valid loss: 0.38568681478500366\n",
            "Validation loss did not improve. 7/50\n",
            "649\n",
            "Valid loss: 0.3855307996273041\n",
            "Validation loss decreased\n",
            "650\n",
            "Valid loss: 0.385534405708313\n",
            "Validation loss did not improve. 1/50\n",
            "651\n",
            "Valid loss: 0.38549181818962097\n",
            "Validation loss decreased\n",
            "652\n",
            "Valid loss: 0.38537925481796265\n",
            "Validation loss decreased\n",
            "653\n",
            "Valid loss: 0.3853440582752228\n",
            "Validation loss decreased\n",
            "654\n",
            "Valid loss: 0.38537362217903137\n",
            "Validation loss did not improve. 1/50\n",
            "655\n",
            "Valid loss: 0.3853459060192108\n",
            "Validation loss did not improve. 2/50\n",
            "656\n",
            "Valid loss: 0.38524580001831055\n",
            "Validation loss decreased\n",
            "657\n",
            "Valid loss: 0.3853306174278259\n",
            "Validation loss did not improve. 1/50\n",
            "658\n",
            "Valid loss: 0.38537007570266724\n",
            "Validation loss did not improve. 2/50\n",
            "659\n",
            "Valid loss: 0.3853839337825775\n",
            "Validation loss did not improve. 3/50\n",
            "660\n",
            "Valid loss: 0.38529688119888306\n",
            "Validation loss did not improve. 4/50\n",
            "661\n",
            "Valid loss: 0.38520532846450806\n",
            "Validation loss decreased\n",
            "662\n",
            "Valid loss: 0.3851834237575531\n",
            "Validation loss decreased\n",
            "663\n",
            "Valid loss: 0.3852318227291107\n",
            "Validation loss did not improve. 1/50\n",
            "664\n",
            "Valid loss: 0.3852829337120056\n",
            "Validation loss did not improve. 2/50\n",
            "665\n",
            "Valid loss: 0.3852284550666809\n",
            "Validation loss did not improve. 3/50\n",
            "666\n",
            "Valid loss: 0.38521450757980347\n",
            "Validation loss did not improve. 4/50\n",
            "667\n",
            "Valid loss: 0.3852238953113556\n",
            "Validation loss did not improve. 5/50\n",
            "668\n",
            "Valid loss: 0.3853320777416229\n",
            "Validation loss did not improve. 6/50\n",
            "669\n",
            "Valid loss: 0.38533222675323486\n",
            "Validation loss did not improve. 7/50\n",
            "670\n",
            "Valid loss: 0.3852126896381378\n",
            "Validation loss did not improve. 8/50\n",
            "671\n",
            "Valid loss: 0.3851555585861206\n",
            "Validation loss decreased\n",
            "672\n",
            "Valid loss: 0.3851069509983063\n",
            "Validation loss decreased\n",
            "673\n",
            "Valid loss: 0.38518840074539185\n",
            "Validation loss did not improve. 1/50\n",
            "674\n",
            "Valid loss: 0.38520967960357666\n",
            "Validation loss did not improve. 2/50\n",
            "675\n",
            "Valid loss: 0.3851197063922882\n",
            "Validation loss did not improve. 3/50\n",
            "676\n",
            "Valid loss: 0.38511788845062256\n",
            "Validation loss did not improve. 4/50\n",
            "677\n",
            "Valid loss: 0.38516953587532043\n",
            "Validation loss did not improve. 5/50\n",
            "678\n",
            "Valid loss: 0.3851023018360138\n",
            "Validation loss decreased\n",
            "679\n",
            "Valid loss: 0.3851322829723358\n",
            "Validation loss did not improve. 1/50\n",
            "680\n",
            "Valid loss: 0.38502272963523865\n",
            "Validation loss decreased\n",
            "681\n",
            "Valid loss: 0.38498225808143616\n",
            "Validation loss decreased\n",
            "682\n",
            "Valid loss: 0.38503140211105347\n",
            "Validation loss did not improve. 1/50\n",
            "683\n",
            "Valid loss: 0.38494357466697693\n",
            "Validation loss decreased\n",
            "684\n",
            "Valid loss: 0.3850015103816986\n",
            "Validation loss did not improve. 1/50\n",
            "685\n",
            "Valid loss: 0.3850262761116028\n",
            "Validation loss did not improve. 2/50\n",
            "686\n",
            "Valid loss: 0.3850170373916626\n",
            "Validation loss did not improve. 3/50\n",
            "687\n",
            "Valid loss: 0.38499513268470764\n",
            "Validation loss did not improve. 4/50\n",
            "688\n",
            "Valid loss: 0.38503944873809814\n",
            "Validation loss did not improve. 5/50\n",
            "689\n",
            "Valid loss: 0.38493552803993225\n",
            "Validation loss decreased\n",
            "690\n",
            "Valid loss: 0.3849596083164215\n",
            "Validation loss did not improve. 1/50\n",
            "691\n",
            "Valid loss: 0.38487598299980164\n",
            "Validation loss decreased\n",
            "692\n",
            "Valid loss: 0.3849116265773773\n",
            "Validation loss did not improve. 1/50\n",
            "693\n",
            "Valid loss: 0.3848622441291809\n",
            "Validation loss decreased\n",
            "694\n",
            "Valid loss: 0.38485008478164673\n",
            "Validation loss decreased\n",
            "695\n",
            "Valid loss: 0.38484612107276917\n",
            "Validation loss decreased\n",
            "696\n",
            "Valid loss: 0.3849051296710968\n",
            "Validation loss did not improve. 1/50\n",
            "697\n",
            "Valid loss: 0.3850158452987671\n",
            "Validation loss did not improve. 2/50\n",
            "698\n",
            "Valid loss: 0.3849583864212036\n",
            "Validation loss did not improve. 3/50\n",
            "699\n",
            "Valid loss: 0.38501274585723877\n",
            "Validation loss did not improve. 4/50\n",
            "700\n",
            "Valid loss: 0.38500064611434937\n",
            "Validation loss did not improve. 5/50\n",
            "701\n",
            "Valid loss: 0.3849654197692871\n",
            "Validation loss did not improve. 6/50\n",
            "702\n",
            "Valid loss: 0.3848961591720581\n",
            "Validation loss did not improve. 7/50\n",
            "703\n",
            "Valid loss: 0.38494178652763367\n",
            "Validation loss did not improve. 8/50\n",
            "704\n",
            "Valid loss: 0.38498228788375854\n",
            "Validation loss did not improve. 9/50\n",
            "705\n",
            "Valid loss: 0.38481470942497253\n",
            "Validation loss decreased\n",
            "706\n",
            "Valid loss: 0.38484448194503784\n",
            "Validation loss did not improve. 1/50\n",
            "707\n",
            "Valid loss: 0.3848778307437897\n",
            "Validation loss did not improve. 2/50\n",
            "708\n",
            "Valid loss: 0.3848491609096527\n",
            "Validation loss did not improve. 3/50\n",
            "709\n",
            "Valid loss: 0.38495710492134094\n",
            "Validation loss did not improve. 4/50\n",
            "710\n",
            "Valid loss: 0.38499200344085693\n",
            "Validation loss did not improve. 5/50\n",
            "711\n",
            "Valid loss: 0.38484442234039307\n",
            "Validation loss did not improve. 6/50\n",
            "712\n",
            "Valid loss: 0.38494962453842163\n",
            "Validation loss did not improve. 7/50\n",
            "713\n",
            "Valid loss: 0.3849964141845703\n",
            "Validation loss did not improve. 8/50\n",
            "714\n",
            "Valid loss: 0.38502833247184753\n",
            "Validation loss did not improve. 9/50\n",
            "715\n",
            "Valid loss: 0.38498052954673767\n",
            "Validation loss did not improve. 10/50\n",
            "716\n",
            "Valid loss: 0.3849220275878906\n",
            "Validation loss did not improve. 11/50\n",
            "717\n",
            "Valid loss: 0.3849979043006897\n",
            "Validation loss did not improve. 12/50\n",
            "718\n",
            "Valid loss: 0.3849954307079315\n",
            "Validation loss did not improve. 13/50\n",
            "719\n",
            "Valid loss: 0.3849526643753052\n",
            "Validation loss did not improve. 14/50\n",
            "720\n",
            "Valid loss: 0.38487738370895386\n",
            "Validation loss did not improve. 15/50\n",
            "721\n",
            "Valid loss: 0.3847189247608185\n",
            "Validation loss decreased\n",
            "722\n",
            "Valid loss: 0.38487496972084045\n",
            "Validation loss did not improve. 1/50\n",
            "723\n",
            "Valid loss: 0.3849438428878784\n",
            "Validation loss did not improve. 2/50\n",
            "724\n",
            "Valid loss: 0.38487347960472107\n",
            "Validation loss did not improve. 3/50\n",
            "725\n",
            "Valid loss: 0.38487014174461365\n",
            "Validation loss did not improve. 4/50\n",
            "726\n",
            "Valid loss: 0.3847877085208893\n",
            "Validation loss did not improve. 5/50\n",
            "727\n",
            "Valid loss: 0.38480228185653687\n",
            "Validation loss did not improve. 6/50\n",
            "728\n",
            "Valid loss: 0.38478410243988037\n",
            "Validation loss did not improve. 7/50\n",
            "729\n",
            "Valid loss: 0.3848068416118622\n",
            "Validation loss did not improve. 8/50\n",
            "730\n",
            "Valid loss: 0.3847756087779999\n",
            "Validation loss did not improve. 9/50\n",
            "731\n",
            "Valid loss: 0.3848140835762024\n",
            "Validation loss did not improve. 10/50\n",
            "732\n",
            "Valid loss: 0.3847319781780243\n",
            "Validation loss did not improve. 11/50\n",
            "733\n",
            "Valid loss: 0.3846903443336487\n",
            "Validation loss decreased\n",
            "734\n",
            "Valid loss: 0.3846668303012848\n",
            "Validation loss decreased\n",
            "735\n",
            "Valid loss: 0.3846597969532013\n",
            "Validation loss decreased\n",
            "736\n",
            "Valid loss: 0.38469287753105164\n",
            "Validation loss did not improve. 1/50\n",
            "737\n",
            "Valid loss: 0.384677529335022\n",
            "Validation loss did not improve. 2/50\n",
            "738\n",
            "Valid loss: 0.3847120404243469\n",
            "Validation loss did not improve. 3/50\n",
            "739\n",
            "Valid loss: 0.38488200306892395\n",
            "Validation loss did not improve. 4/50\n",
            "740\n",
            "Valid loss: 0.38476645946502686\n",
            "Validation loss did not improve. 5/50\n",
            "741\n",
            "Valid loss: 0.3847242593765259\n",
            "Validation loss did not improve. 6/50\n",
            "742\n",
            "Valid loss: 0.3849383294582367\n",
            "Validation loss did not improve. 7/50\n",
            "743\n",
            "Valid loss: 0.3848879039287567\n",
            "Validation loss did not improve. 8/50\n",
            "744\n",
            "Valid loss: 0.3847743272781372\n",
            "Validation loss did not improve. 9/50\n",
            "745\n",
            "Valid loss: 0.38480839133262634\n",
            "Validation loss did not improve. 10/50\n",
            "746\n",
            "Valid loss: 0.3849111795425415\n",
            "Validation loss did not improve. 11/50\n",
            "747\n",
            "Valid loss: 0.3848399817943573\n",
            "Validation loss did not improve. 12/50\n",
            "748\n",
            "Valid loss: 0.3848777711391449\n",
            "Validation loss did not improve. 13/50\n",
            "749\n",
            "Valid loss: 0.3848230242729187\n",
            "Validation loss did not improve. 14/50\n",
            "750\n",
            "Valid loss: 0.3847822844982147\n",
            "Validation loss did not improve. 15/50\n",
            "751\n",
            "Valid loss: 0.38477447628974915\n",
            "Validation loss did not improve. 16/50\n",
            "752\n",
            "Valid loss: 0.3846968412399292\n",
            "Validation loss did not improve. 17/50\n",
            "753\n",
            "Valid loss: 0.3847300410270691\n",
            "Validation loss did not improve. 18/50\n",
            "754\n",
            "Valid loss: 0.3848460614681244\n",
            "Validation loss did not improve. 19/50\n",
            "755\n",
            "Valid loss: 0.3848990797996521\n",
            "Validation loss did not improve. 20/50\n",
            "756\n",
            "Valid loss: 0.3847455680370331\n",
            "Validation loss did not improve. 21/50\n",
            "757\n",
            "Valid loss: 0.384808212518692\n",
            "Validation loss did not improve. 22/50\n",
            "758\n",
            "Valid loss: 0.38491401076316833\n",
            "Validation loss did not improve. 23/50\n",
            "759\n",
            "Valid loss: 0.3848743438720703\n",
            "Validation loss did not improve. 24/50\n",
            "760\n",
            "Valid loss: 0.3848559260368347\n",
            "Validation loss did not improve. 25/50\n",
            "761\n",
            "Valid loss: 0.3847258687019348\n",
            "Validation loss did not improve. 26/50\n",
            "762\n",
            "Valid loss: 0.3847450017929077\n",
            "Validation loss did not improve. 27/50\n",
            "763\n",
            "Valid loss: 0.38462695479393005\n",
            "Validation loss decreased\n",
            "764\n",
            "Valid loss: 0.38459312915802\n",
            "Validation loss decreased\n",
            "765\n",
            "Valid loss: 0.3846864700317383\n",
            "Validation loss did not improve. 1/50\n",
            "766\n",
            "Valid loss: 0.38458675146102905\n",
            "Validation loss decreased\n",
            "767\n",
            "Valid loss: 0.38468852639198303\n",
            "Validation loss did not improve. 1/50\n",
            "768\n",
            "Valid loss: 0.3846270442008972\n",
            "Validation loss did not improve. 2/50\n",
            "769\n",
            "Valid loss: 0.3846007287502289\n",
            "Validation loss did not improve. 3/50\n",
            "770\n",
            "Valid loss: 0.3846699893474579\n",
            "Validation loss did not improve. 4/50\n",
            "771\n",
            "Valid loss: 0.3845832049846649\n",
            "Validation loss decreased\n",
            "772\n",
            "Valid loss: 0.38465481996536255\n",
            "Validation loss did not improve. 1/50\n",
            "773\n",
            "Valid loss: 0.3847171664237976\n",
            "Validation loss did not improve. 2/50\n",
            "774\n",
            "Valid loss: 0.3846772611141205\n",
            "Validation loss did not improve. 3/50\n",
            "775\n",
            "Valid loss: 0.3846370577812195\n",
            "Validation loss did not improve. 4/50\n",
            "776\n",
            "Valid loss: 0.38464516401290894\n",
            "Validation loss did not improve. 5/50\n",
            "777\n",
            "Valid loss: 0.38460955023765564\n",
            "Validation loss did not improve. 6/50\n",
            "778\n",
            "Valid loss: 0.3847619593143463\n",
            "Validation loss did not improve. 7/50\n",
            "779\n",
            "Valid loss: 0.3846781551837921\n",
            "Validation loss did not improve. 8/50\n",
            "780\n",
            "Valid loss: 0.38459518551826477\n",
            "Validation loss did not improve. 9/50\n",
            "781\n",
            "Valid loss: 0.38459187746047974\n",
            "Validation loss did not improve. 10/50\n",
            "782\n",
            "Valid loss: 0.3845086991786957\n",
            "Validation loss decreased\n",
            "783\n",
            "Valid loss: 0.3845303952693939\n",
            "Validation loss did not improve. 1/50\n",
            "784\n",
            "Valid loss: 0.384612113237381\n",
            "Validation loss did not improve. 2/50\n",
            "785\n",
            "Valid loss: 0.3844988942146301\n",
            "Validation loss decreased\n",
            "786\n",
            "Valid loss: 0.3844554126262665\n",
            "Validation loss decreased\n",
            "787\n",
            "Valid loss: 0.3843929171562195\n",
            "Validation loss decreased\n",
            "788\n",
            "Valid loss: 0.3843454420566559\n",
            "Validation loss decreased\n",
            "789\n",
            "Valid loss: 0.3844307065010071\n",
            "Validation loss did not improve. 1/50\n",
            "790\n",
            "Valid loss: 0.3843463957309723\n",
            "Validation loss did not improve. 2/50\n",
            "791\n",
            "Valid loss: 0.3843405842781067\n",
            "Validation loss decreased\n",
            "792\n",
            "Valid loss: 0.3843849003314972\n",
            "Validation loss did not improve. 1/50\n",
            "793\n",
            "Valid loss: 0.3844418525695801\n",
            "Validation loss did not improve. 2/50\n",
            "794\n",
            "Valid loss: 0.3843662142753601\n",
            "Validation loss did not improve. 3/50\n",
            "795\n",
            "Valid loss: 0.38442930579185486\n",
            "Validation loss did not improve. 4/50\n",
            "796\n",
            "Valid loss: 0.3843521475791931\n",
            "Validation loss did not improve. 5/50\n",
            "797\n",
            "Valid loss: 0.3844310939311981\n",
            "Validation loss did not improve. 6/50\n",
            "798\n",
            "Valid loss: 0.38441866636276245\n",
            "Validation loss did not improve. 7/50\n",
            "799\n",
            "Valid loss: 0.3843076825141907\n",
            "Validation loss decreased\n",
            "800\n",
            "Valid loss: 0.3844132125377655\n",
            "Validation loss did not improve. 1/50\n",
            "801\n",
            "Valid loss: 0.384425550699234\n",
            "Validation loss did not improve. 2/50\n",
            "802\n",
            "Valid loss: 0.3843880295753479\n",
            "Validation loss did not improve. 3/50\n",
            "803\n",
            "Valid loss: 0.3843338191509247\n",
            "Validation loss did not improve. 4/50\n",
            "804\n",
            "Valid loss: 0.3842514753341675\n",
            "Validation loss decreased\n",
            "805\n",
            "Valid loss: 0.3843197226524353\n",
            "Validation loss did not improve. 1/50\n",
            "806\n",
            "Valid loss: 0.38434112071990967\n",
            "Validation loss did not improve. 2/50\n",
            "807\n",
            "Valid loss: 0.3843977153301239\n",
            "Validation loss did not improve. 3/50\n",
            "808\n",
            "Valid loss: 0.38439828157424927\n",
            "Validation loss did not improve. 4/50\n",
            "809\n",
            "Valid loss: 0.3844284117221832\n",
            "Validation loss did not improve. 5/50\n",
            "810\n",
            "Valid loss: 0.3844509422779083\n",
            "Validation loss did not improve. 6/50\n",
            "811\n",
            "Valid loss: 0.3843451738357544\n",
            "Validation loss did not improve. 7/50\n",
            "812\n",
            "Valid loss: 0.3843774199485779\n",
            "Validation loss did not improve. 8/50\n",
            "813\n",
            "Valid loss: 0.3843819499015808\n",
            "Validation loss did not improve. 9/50\n",
            "814\n",
            "Valid loss: 0.3842954635620117\n",
            "Validation loss did not improve. 10/50\n",
            "815\n",
            "Valid loss: 0.3843463659286499\n",
            "Validation loss did not improve. 11/50\n",
            "816\n",
            "Valid loss: 0.3842732608318329\n",
            "Validation loss did not improve. 12/50\n",
            "817\n",
            "Valid loss: 0.3842329978942871\n",
            "Validation loss decreased\n",
            "818\n",
            "Valid loss: 0.3841186761856079\n",
            "Validation loss decreased\n",
            "819\n",
            "Valid loss: 0.38417091965675354\n",
            "Validation loss did not improve. 1/50\n",
            "820\n",
            "Valid loss: 0.3842286467552185\n",
            "Validation loss did not improve. 2/50\n",
            "821\n",
            "Valid loss: 0.38417795300483704\n",
            "Validation loss did not improve. 3/50\n",
            "822\n",
            "Valid loss: 0.38424351811408997\n",
            "Validation loss did not improve. 4/50\n",
            "823\n",
            "Valid loss: 0.3841976225376129\n",
            "Validation loss did not improve. 5/50\n",
            "824\n",
            "Valid loss: 0.3841436803340912\n",
            "Validation loss did not improve. 6/50\n",
            "825\n",
            "Valid loss: 0.38431331515312195\n",
            "Validation loss did not improve. 7/50\n",
            "826\n",
            "Valid loss: 0.38426607847213745\n",
            "Validation loss did not improve. 8/50\n",
            "827\n",
            "Valid loss: 0.38434404134750366\n",
            "Validation loss did not improve. 9/50\n",
            "828\n",
            "Valid loss: 0.3842509090900421\n",
            "Validation loss did not improve. 10/50\n",
            "829\n",
            "Valid loss: 0.38423392176628113\n",
            "Validation loss did not improve. 11/50\n",
            "830\n",
            "Valid loss: 0.3842102587223053\n",
            "Validation loss did not improve. 12/50\n",
            "831\n",
            "Valid loss: 0.38427087664604187\n",
            "Validation loss did not improve. 13/50\n",
            "832\n",
            "Valid loss: 0.384255051612854\n",
            "Validation loss did not improve. 14/50\n",
            "833\n",
            "Valid loss: 0.3841553330421448\n",
            "Validation loss did not improve. 15/50\n",
            "834\n",
            "Valid loss: 0.384194016456604\n",
            "Validation loss did not improve. 16/50\n",
            "835\n",
            "Valid loss: 0.3841620087623596\n",
            "Validation loss did not improve. 17/50\n",
            "836\n",
            "Valid loss: 0.38421866297721863\n",
            "Validation loss did not improve. 18/50\n",
            "837\n",
            "Valid loss: 0.3842620849609375\n",
            "Validation loss did not improve. 19/50\n",
            "838\n",
            "Valid loss: 0.38425201177597046\n",
            "Validation loss did not improve. 20/50\n",
            "839\n",
            "Valid loss: 0.38433223962783813\n",
            "Validation loss did not improve. 21/50\n",
            "840\n",
            "Valid loss: 0.38425177335739136\n",
            "Validation loss did not improve. 22/50\n",
            "841\n",
            "Valid loss: 0.38426560163497925\n",
            "Validation loss did not improve. 23/50\n",
            "842\n",
            "Valid loss: 0.3842530846595764\n",
            "Validation loss did not improve. 24/50\n",
            "843\n",
            "Valid loss: 0.38425934314727783\n",
            "Validation loss did not improve. 25/50\n",
            "844\n",
            "Valid loss: 0.38419896364212036\n",
            "Validation loss did not improve. 26/50\n",
            "845\n",
            "Valid loss: 0.38417288661003113\n",
            "Validation loss did not improve. 27/50\n",
            "846\n",
            "Valid loss: 0.3841051757335663\n",
            "Validation loss decreased\n",
            "847\n",
            "Valid loss: 0.3842781186103821\n",
            "Validation loss did not improve. 1/50\n",
            "848\n",
            "Valid loss: 0.3843861222267151\n",
            "Validation loss did not improve. 2/50\n",
            "849\n",
            "Valid loss: 0.38433837890625\n",
            "Validation loss did not improve. 3/50\n",
            "850\n",
            "Valid loss: 0.38426682353019714\n",
            "Validation loss did not improve. 4/50\n",
            "851\n",
            "Valid loss: 0.38424187898635864\n",
            "Validation loss did not improve. 5/50\n",
            "852\n",
            "Valid loss: 0.3842732310295105\n",
            "Validation loss did not improve. 6/50\n",
            "853\n",
            "Valid loss: 0.384277880191803\n",
            "Validation loss did not improve. 7/50\n",
            "854\n",
            "Valid loss: 0.3842439651489258\n",
            "Validation loss did not improve. 8/50\n",
            "855\n",
            "Valid loss: 0.3842354416847229\n",
            "Validation loss did not improve. 9/50\n",
            "856\n",
            "Valid loss: 0.38417142629623413\n",
            "Validation loss did not improve. 10/50\n",
            "857\n",
            "Valid loss: 0.38418227434158325\n",
            "Validation loss did not improve. 11/50\n",
            "858\n",
            "Valid loss: 0.38420167565345764\n",
            "Validation loss did not improve. 12/50\n",
            "859\n",
            "Valid loss: 0.3841172456741333\n",
            "Validation loss did not improve. 13/50\n",
            "860\n",
            "Valid loss: 0.3841796815395355\n",
            "Validation loss did not improve. 14/50\n",
            "861\n",
            "Valid loss: 0.38424447178840637\n",
            "Validation loss did not improve. 15/50\n",
            "862\n",
            "Valid loss: 0.3842351734638214\n",
            "Validation loss did not improve. 16/50\n",
            "863\n",
            "Valid loss: 0.38426509499549866\n",
            "Validation loss did not improve. 17/50\n",
            "864\n",
            "Valid loss: 0.38442468643188477\n",
            "Validation loss did not improve. 18/50\n",
            "865\n",
            "Valid loss: 0.3841734826564789\n",
            "Validation loss did not improve. 19/50\n",
            "866\n",
            "Valid loss: 0.3842107355594635\n",
            "Validation loss did not improve. 20/50\n",
            "867\n",
            "Valid loss: 0.3840940594673157\n",
            "Validation loss decreased\n",
            "868\n",
            "Valid loss: 0.3841628134250641\n",
            "Validation loss did not improve. 1/50\n",
            "869\n",
            "Valid loss: 0.3841124176979065\n",
            "Validation loss did not improve. 2/50\n",
            "870\n",
            "Valid loss: 0.3840464651584625\n",
            "Validation loss decreased\n",
            "871\n",
            "Valid loss: 0.3840833008289337\n",
            "Validation loss did not improve. 1/50\n",
            "872\n",
            "Valid loss: 0.3841678202152252\n",
            "Validation loss did not improve. 2/50\n",
            "873\n",
            "Valid loss: 0.3841393291950226\n",
            "Validation loss did not improve. 3/50\n",
            "874\n",
            "Valid loss: 0.3842109441757202\n",
            "Validation loss did not improve. 4/50\n",
            "875\n",
            "Valid loss: 0.38416770100593567\n",
            "Validation loss did not improve. 5/50\n",
            "876\n",
            "Valid loss: 0.38405731320381165\n",
            "Validation loss did not improve. 6/50\n",
            "877\n",
            "Valid loss: 0.38409310579299927\n",
            "Validation loss did not improve. 7/50\n",
            "878\n",
            "Valid loss: 0.38398316502571106\n",
            "Validation loss decreased\n",
            "879\n",
            "Valid loss: 0.38392966985702515\n",
            "Validation loss decreased\n",
            "880\n",
            "Valid loss: 0.38402652740478516\n",
            "Validation loss did not improve. 1/50\n",
            "881\n",
            "Valid loss: 0.3840879201889038\n",
            "Validation loss did not improve. 2/50\n",
            "882\n",
            "Valid loss: 0.3841732144355774\n",
            "Validation loss did not improve. 3/50\n",
            "883\n",
            "Valid loss: 0.3841994106769562\n",
            "Validation loss did not improve. 4/50\n",
            "884\n",
            "Valid loss: 0.38421568274497986\n",
            "Validation loss did not improve. 5/50\n",
            "885\n",
            "Valid loss: 0.38412967324256897\n",
            "Validation loss did not improve. 6/50\n",
            "886\n",
            "Valid loss: 0.3841342031955719\n",
            "Validation loss did not improve. 7/50\n",
            "887\n",
            "Valid loss: 0.3840744197368622\n",
            "Validation loss did not improve. 8/50\n",
            "888\n",
            "Valid loss: 0.38413727283477783\n",
            "Validation loss did not improve. 9/50\n",
            "889\n",
            "Valid loss: 0.38412386178970337\n",
            "Validation loss did not improve. 10/50\n",
            "890\n",
            "Valid loss: 0.3842020332813263\n",
            "Validation loss did not improve. 11/50\n",
            "891\n",
            "Valid loss: 0.3842543363571167\n",
            "Validation loss did not improve. 12/50\n",
            "892\n",
            "Valid loss: 0.3842281401157379\n",
            "Validation loss did not improve. 13/50\n",
            "893\n",
            "Valid loss: 0.3843534588813782\n",
            "Validation loss did not improve. 14/50\n",
            "894\n",
            "Valid loss: 0.38429293036460876\n",
            "Validation loss did not improve. 15/50\n",
            "895\n",
            "Valid loss: 0.3843216300010681\n",
            "Validation loss did not improve. 16/50\n",
            "896\n",
            "Valid loss: 0.38417622447013855\n",
            "Validation loss did not improve. 17/50\n",
            "897\n",
            "Valid loss: 0.38408705592155457\n",
            "Validation loss did not improve. 18/50\n",
            "898\n",
            "Valid loss: 0.3840651512145996\n",
            "Validation loss did not improve. 19/50\n",
            "899\n",
            "Valid loss: 0.384141743183136\n",
            "Validation loss did not improve. 20/50\n",
            "900\n",
            "Valid loss: 0.38413429260253906\n",
            "Validation loss did not improve. 21/50\n",
            "901\n",
            "Valid loss: 0.38430890440940857\n",
            "Validation loss did not improve. 22/50\n",
            "902\n",
            "Valid loss: 0.3842608630657196\n",
            "Validation loss did not improve. 23/50\n",
            "903\n",
            "Valid loss: 0.38422247767448425\n",
            "Validation loss did not improve. 24/50\n",
            "904\n",
            "Valid loss: 0.38427451252937317\n",
            "Validation loss did not improve. 25/50\n",
            "905\n",
            "Valid loss: 0.38423213362693787\n",
            "Validation loss did not improve. 26/50\n",
            "906\n",
            "Valid loss: 0.3843517303466797\n",
            "Validation loss did not improve. 27/50\n",
            "907\n",
            "Valid loss: 0.3844355046749115\n",
            "Validation loss did not improve. 28/50\n",
            "908\n",
            "Valid loss: 0.38437286019325256\n",
            "Validation loss did not improve. 29/50\n",
            "909\n",
            "Valid loss: 0.38421547412872314\n",
            "Validation loss did not improve. 30/50\n",
            "910\n",
            "Valid loss: 0.3842579424381256\n",
            "Validation loss did not improve. 31/50\n",
            "911\n",
            "Valid loss: 0.38425031304359436\n",
            "Validation loss did not improve. 32/50\n",
            "912\n",
            "Valid loss: 0.38430503010749817\n",
            "Validation loss did not improve. 33/50\n",
            "913\n",
            "Valid loss: 0.3843485116958618\n",
            "Validation loss did not improve. 34/50\n",
            "914\n",
            "Valid loss: 0.3842255771160126\n",
            "Validation loss did not improve. 35/50\n",
            "915\n",
            "Valid loss: 0.3842245638370514\n",
            "Validation loss did not improve. 36/50\n",
            "916\n",
            "Valid loss: 0.3842891454696655\n",
            "Validation loss did not improve. 37/50\n",
            "917\n",
            "Valid loss: 0.38424545526504517\n",
            "Validation loss did not improve. 38/50\n",
            "918\n",
            "Valid loss: 0.3842574954032898\n",
            "Validation loss did not improve. 39/50\n",
            "919\n",
            "Valid loss: 0.3842134475708008\n",
            "Validation loss did not improve. 40/50\n",
            "920\n",
            "Valid loss: 0.3842516541481018\n",
            "Validation loss did not improve. 41/50\n",
            "921\n",
            "Valid loss: 0.3842681050300598\n",
            "Validation loss did not improve. 42/50\n",
            "922\n",
            "Valid loss: 0.384263813495636\n",
            "Validation loss did not improve. 43/50\n",
            "923\n",
            "Valid loss: 0.384280264377594\n",
            "Validation loss did not improve. 44/50\n",
            "924\n",
            "Valid loss: 0.38417190313339233\n",
            "Validation loss did not improve. 45/50\n",
            "925\n",
            "Valid loss: 0.3841344714164734\n",
            "Validation loss did not improve. 46/50\n",
            "926\n",
            "Valid loss: 0.3841696083545685\n",
            "Validation loss did not improve. 47/50\n",
            "927\n",
            "Valid loss: 0.38419345021247864\n",
            "Validation loss did not improve. 48/50\n",
            "928\n",
            "Valid loss: 0.3842870891094208\n",
            "Validation loss did not improve. 49/50\n",
            "929\n",
            "Valid loss: 0.3842149078845978\n",
            "Validation loss did not improve. 50/50\n",
            "Early stopping triggered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# epochs vs. train && epochs vs.valid\n",
        "def plot_loss_curves(epochs, train_loss, valid_loss):\n",
        "    plt.plot(epochs, train_loss, label=\"Train loss\")\n",
        "    plt.plot(epochs, valid_loss, label=\"Valid loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MSE\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "zkisfuYsU7qz"
      },
      "execution_count": 924,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(np.linspace(1, stopping, stopping), train_loss[:-1], valid_loss[:-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "kZl9ePMdU7tZ",
        "outputId": "34bda7c9-6782-44f5-8827-5d75a50c5522"
      },
      "execution_count": 925,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmGRCJH6_5uj",
        "outputId": "c5f1994b-745d-4bd3-e4de-8fff30f20bf6"
      },
      "execution_count": 926,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "929"
            ]
          },
          "metadata": {},
          "execution_count": 926
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_output = model.forward(test_x_ss)\n",
        "test_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE3saPfJU7xy",
        "outputId": "0e77170a-7178-4d98-93c9-b7ae5602893f"
      },
      "execution_count": 927,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([240, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 927
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_test = criterion(test_output, test_y)\n",
        "\n",
        "print(\"The MSE of test set:\", mse_test.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6G-tkv4n1Zh",
        "outputId": "aa1fd9d1-7c9c-4f42-c73d-a56212940d09"
      },
      "execution_count": 928,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MSE of test set: 0.38019827008247375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model!"
      ],
      "metadata": {
        "id": "0k-tTFrOr3-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path to save the model in Google Drive\n",
        "folder_path = '/content/drive/My Drive/colab-models/Assignment4'\n",
        "model_path = os.path.join(folder_path, 'TuneV2.9_MLP_model.pth')\n",
        "\n",
        "# Create the folder if it does not exist\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)"
      ],
      "metadata": {
        "id": "ba0YHNDwr3A8"
      },
      "execution_count": 929,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "F9GFdKZYr_ZI"
      },
      "execution_count": 930,
      "outputs": []
    }
  ]
}